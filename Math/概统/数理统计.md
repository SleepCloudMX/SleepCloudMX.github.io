<h1 align="center">概率论与数理统计</h1>

$$
\text{眠云跂石整理}

% 字符
\renewcommand{\i}{\textup{i}}
\newcommand{\e}{\textup{e}}
\newcommand{\ve}{\varepsilon}
\newcommand{\Beta}{\mathit{B}}
\newcommand{\SS}{\mathrm{SS}}

% 上下标
\newcommand{\trans}{^\mathrm{T}}
\newcommand{\inv}{^{-1}}
\newcommand{\adj}[1]{^{\pqty{#1^*}}}

% 特定内容
\newcommand{\oneton}{1,2,\cdots,n}
\newcommand{\oneto}[1]{1,2,\cdots,#1}

\newcommand{\ssto}[3]{#1_1 #3 #1_2 #3 \cdots #3 #1_{#2}}
\newcommand{\ssup}[3]{#1^1 #3 #1^2 #3 \cdots #3 #1^{#2}}
\newcommand{\soneto}[2]{\ssto{#1}{#2}{,}}
\newcommand{\splus}[2]{\ssto{#1}{#2}{+}}

\newcommand{\aqty}[1]{\expval{#1}}
\newcommand{\pbqty}[1]{\left(#1\right]}
\newcommand{\bpqty}[1]{\left[#1\right)}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}

\newcommand{\ccdots}{\cdot\cdots\cdot}

% 下面几个只是为了方便一点点而已
\newcommand{\dx}{\dd{x}}
\newcommand{\dy}{\dd{y}}
\newcommand{\dz}{\dd{z}}
\newcommand{\dt}{\dd{t}}
\newcommand{\ds}{\dd{s}}

% 如果只使用 \dd{x}\dd{y} 的话, 中间会有多余的间隔.
\newcommand{\ddd}[2]{\,\mathrm{d}#1\mathrm{d}#2}
\newcommand{\dxdy}{\,\mathrm{d}x\mathrm{d}y}
\newcommand{\dydz}{\,\mathrm{d}y\mathrm{d}z}
\newcommand{\dzdx}{\,\mathrm{d}z\mathrm{d}x}
\newcommand{\dudv}{\,\mathrm{d}u\mathrm{d}v}
\newcommand{\dxdydz}{\,\mathrm{d}x\mathrm{d}y\mathrm{d}z}

% 矩阵的宏指令
\newcommand{\pmcmn}[3]{\begin{pmatrix}
	#1_{11} & #1_{12} & \cdots & #1_{1#3} \\
	#1_{21} & #1_{22} & \cdots & #1_{n#3} \\
	\vdots & \vdots && \vdots \\
	#1_{#2 1} & #1_{#2 2} & \cdots & #2_{n#3} \\
\end{pmatrix}}

\newcommand{\pmc}[1]{\pmcmn{#1}{n}{n}}

\newcommand{\pvcn}[2]{\begin{pmatrix}
	#1_1 \\ #1_2 \\ \vdots \\ #1_{#2}
\end{pmatrix}}

\newcommand{\pvc}[1]{\pvcn{#1}{n}}

\newcommand{\pto}{\overset{P}{\to}}



% 函数名
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Corr}{Corr}

% 运算符
\newcommand{\dint}{\displaystyle\int}
\newcommand{\inti}{\dint_{-\infty}^{+\infty}}
\newcommand{\intoi}{\dint_0^{+\infty}}

\newcommand{\intl}{\displaystyle\int\limits}
\newcommand{\iintl}{\displaystyle\iint\limits}
\newcommand{\iiintl}{\displaystyle\iiint\limits}

\newcommand{\dsum}{\displaystyle\sum}
\newcommand{\nsum}{\dsum_{n=1}^\infty}
\newcommand{\nosum}{\dsum_{n=0}^\infty}
\newcommand{\insum}{\dsum_{i=1}^n}

\newcommand{\dprod}{\displaystyle\prod}
\newcommand{\nprod}{\dprod_{n=1}^\infty}

\newcommand{\xlim}{\lim\limits_{x\to x_0}}
\newcommand{\nlim}{\lim\limits_{n\to\infty}}
\newcommand{\clim}[1]{\lim\limits_{#1\to\infty}}
\newcommand{\ulim}{\overline\lim\limits_{n\to\infty}}
\newcommand{\dlim}{\underline\lim\limits_{n\to\infty}}
% 注意这里的 d 是 down, 而不是 displaystyle

% 缩写
\newcommand{\bm}[1]{\boldsymbol{#1}}
\newcommand{\LRA}{\Leftrightarrow}
\newcommand{\RLA}{\Leftrightarrow}
\newcommand{\LA}{\Leftarrow}
\newcommand{\RA}{\Rightarrow}

\newcommand{\lra}{\leftrightarrow}
\newcommand{\rla}{\leftrightarrow}
\newcommand{\la}{\leftarrow}
\newcommand{\ra}{\rightarrow}

\newcommand{\QRLA}{\quad\RLA\quad}
\newcommand{\QRA}{\quad\RA\quad}
\newcommand{\LLRA}{\Longleftrightarrow}

\newcommand{\QNRA}{\quad\nRightarrow\quad}
\newcommand{\qnra}{\quad\nrightarrow\quad}

% displaytsyle 的指令缩写
\newcommand{\ddv}{\displaystyle\dv}
\newcommand{\dpdv}{\displaystyle\pdv}
$$

[TOC]

# 第 4 章	参数估计

## 4.1	基本概念与性质

### 4.1.1	基本概念与常用统计图

**总体**（母体）是概率分布族的一员.

**总体分布**	离散性（概率函数），连续型（概率密度函数）

**单参数分布族**	

**非参数总体**	

**样本大小 (容量)**	

---

**常用统计图**

1. **频数分布表**

   | 组号 | 区间     | 频数 $n_i$ | 频率 $f_i$ |
   | ---- | -------- | ---------- | ---------- |
   | 1    | $(1, 2]$ | 2          | 0.40       |
   | 2    | $(2, 3]$ | 3          | 0.60       |
   | 合计 |          | 5          | 1.00       |

2. **频率直方图**	以 $ \dfrac{f_i}{\Delta t_i} $ 为高. 所有小矩形的面积和为 1.

3. **条形图**	一般用于小样本离散性随机变量总体分布.

---

### 4.1.2	经验分布函数与格列文科定理

**经验分布函数 (样本分布函数)**	$ F_n(x) = \Bqty{ \soneto{X}{n} \text{ 中不大于 $x$ 的个数} } / n $.

即将 $X$ 的样本值 $\soneto{x}{n}$ 从小到大重排后, 定义经验分布函数如下.
$$
\underbrace{x_{(1)}, \cdots, x_{(1)}}_{n_1},
\underbrace{x_{(2)}, \cdots, x_{(2)}}_{n_2}, \cdots
\underbrace{x_{(m)}, \cdots, x_{(m)}}_{n_m},

\\
F_n(x) = \begin{cases}
	0, & x < x_{(1)}, \\
	\dfrac{1}{n} \dsum_{i=1}^k n_i, & x_{(k)} \le x < x_{(k+1)} \\
	1, & x \ge x_{(m)}
\end{cases}
$$

1. $ 0 \le F_n(x) \le 1 $.
2. $F_n(x)$ 单调不减.
3. $ F_n(-\infty) = 0,\, F_n(+\infty) = 1 $.
4. $F_n(x)$ 右连续.

---

**格列文科定理**	对于任意实数 $x$, 经验分布函数 $F_n(x)$ 以概率 1 一致收敛于总体分布函数 $F(x)$, 即
$$
P\Bqty{
	\nlim \sup_{-\infty < x < +\infty}
	\vqty{F_n(x) - F(x)} = 0
} = 1.
$$

- 经验分布函数不确定, 不唯一, 所以在极限外套一个 P.

---

### 4.1.3	常用统计量及其性质

**统计量**	只依赖于样本，而不依赖于其未知参数.

- 样本的统计量为 $ g(\soneto{X}{n}) $.
- 统计量的观测值为 $g(\soneto{x}{n})$.

**样本均值**	$ \overline{X} = a_1 = \dfrac{1}{n} \insum{X_i} $.

- 其观测值记为 $ \overline{x} = \dfrac{1}{n} \insum x_i $.

- 对于一般分布

  - $ E(\overline{X}) = E(X_i) $.

  - $ D(\overline{X}) = \dfrac{1}{n^2} D(\splus{X}{n}) = \dfrac{1}{n} D(X_i) $.

- :star: 设总体有 $N$ 个数据 $ \soneto{a}{N} $, 均值为 $ \mu = \dfrac{1}{N} \dsum_{i=1}^N a_i $, 方差为 $ \sigma^2 = \dfrac{1}{N} \dsum_{i=1}^N (a_i - \mu)^2 $.

  从总体中抽取 $n$ 个值 $ \soneto{X}{n} $ 作为样本, 则

  - $ E(\overline{X}) = \mu $.
  - $ D(\overline{X}) = \dfrac{N-n}{N-1} \dfrac{\sigma^2}{n} $.

  当 $ N \to +\infty $ 时, 即抽取的样本相互独立时, 有 $ D(\overline{X}) \sim \dfrac{\sigma^2}{n} $.

**样本离差平方和**	$ \mathrm{SS} = \insum (X_i - \overline{X})^2 $.

- 其观测值记为 $ \mathrm{ss} = \insum (x_i - \overline{x})^2 $.

**样本方差**	$ S^2 = \dfrac{1}{n-1} \dsum_{i=1}^n (X_i - \overline{X})^2 $.

- 其观测值记为 $ s^2 $.
- 标准差又称<u>均方差</u>, 样本标准差的观测值记为 $s$.
- 对于一般分布, 有 $ E(S^2) = \sigma^2 $.
- 对于正态分布, 有 $ D(S^2) = D\pqty{\dfrac{\sigma^2}{n-1} \chi_{n-1}^2} = \dfrac{2\sigma^4}{n-1} $. :star: 

**样本原点矩**	$ a_k = \dfrac{1}{n} \insum X_i^k $.

- 或使用 $A_k$ 表示样本原点矩, 用 $a_k$ 表示其观测值.

**样本中心矩**	$ m_k = \dfrac{1}{n} \displaystyle \sum_{i=1}^n (X_i - \overline{X})^k $.

- 或使用 $B_k$ 表示样本中心距, 用 $b_k$ 表示其观测值.
- 矩称为<u>理论矩</u>，样本矩称为<u>经验矩</u>，即经验分布函数的矩.
- $ m_2 = \dfrac{n-1}{n} S^2 $.

**样本协方差**	$ S_{XY} = \dfrac{1}{n-1} \insum (X_i - \overline{X}) (Y_i - \overline{Y}) $.

- 其观测值记为 $s_{_{XY}}$.

**样本相关系数**	$ \rho_{XY} = \dfrac{S_{XY}}{S_X S_Y} $.

- 其中 $S_{X}$ 和 $S_{Y}$ 为样本均方差. 其观测值为 $ \rho_{XY} = \dfrac{s_{_{XY}}}{s_{_X} s_{_Y}} $.

---

样本的 **众数** 记为 $M_0$.

**次序统计量**	$ X_{(1)} \le X_{(2)} \le \cdots \le X_{(n)} $.

**样本中位数**	$ \hat{m} = M_e = \begin{cases} X_{((n+1)/2)}, & n \text{ 为奇数,} \\ (X_{(n/2)} + X_{(n/2+1)}) / 2, & n \text{ 为偶数.} \end{cases} $ 

---

**偏态系数**

- 计算公式
  - 简单偏态系数 $ \mathrm{SK} = \dfrac{m_3}{\sigma^3} = \dfrac{\sum(X - \overline{X})^3}{\sigma^3 \cdot N} $.
  - 加权偏态系数 $ \mathrm{SK} = \dfrac{\sum (X - \overline{X})^3 F}{\sigma^3 \sum F} $.
- 取值说明
  - $\mathrm{SK} = 0$ 表示数据为完全的对称分布.
  - $ \mathrm{SK} > 0 $ 表示数据为 **正偏态** (或 **右偏态**).
  - $ \mathrm{SK} < 0 $ 表示数据为 **负偏态** (或 **左偏态**).

## 4.2	点估计

### 4.2.1	矩估计法

$$
\alpha_m = \inti x^m f(x; \theta_1, \cdots, \theta_2) \dd{x}
\approx a_m = \sum_{i=1}^n X_i^m / n
$$

取 $ m = \oneto{k} $，联立方程组即得 $ \theta_i \approx \hat{\theta}_i(X_1, \cdots, X_n) $.

- $ \hat\theta_i(\soneto{X}{n}) $ 称为矩估计量.
- $ \hat\theta_i(\soneto{x}{n}) $ 称为矩估计值. (其它估计相关名称类似)

**变异系数**	$ \sigma/\mu $.

---

:crescent_moon: 对于任意均值 $\mu$ 与方差 $\sigma^2$ 存在的总体, 有矩估计:
$$
\begin{cases}
	\mu = \dfrac{1}{n} \insum X_i \\
	\sigma^2 + \mu^2 = \dfrac{1}{n} \insum X_i^2 \\
\end{cases}
\QRA
\begin{cases}
	\hat\mu = \overline{X} \\
	\hat{\sigma^2} = \dfrac{\SS}{n} \\
\end{cases}
$$

### 4.2.2	极大似然估计法

样本 $(\soneto{X}{n})$ 的总体分布函数 (样本似然函数) 为
$$
\begin{align}
L(x_1, \cdots, x_n,; \theta_1, \cdots, \theta_k)
&= \prod_{i=1}^n f(x_i; \soneto{\theta}{n})
% f(x_1; \theta_1, \cdots, \theta_k) f(x_2; \theta_1, \cdots, \theta_k) \cdots f(x_n; \theta_1, \cdots, \theta_k)
\\
L(X_1, \cdots, X_n; \theta_1^*, \cdots, \theta_k^*)
&= 
\max_{\theta_1, \cdots, \theta_k} L(X_1, \cdots, X_n; \theta_1, \cdots, \theta_k)
\end{align}
$$
欲得到极大似然估计，解如下似然方程组
$$
\pdv{\ln{L}}{\theta_i} = 0\quad (i = \oneto{k})
$$

### 4.2.3	贝叶斯估计法

先验分布，先验概率. 允许使用主观概率.

设总体有概率密度 $f(X, \theta)$，抽样本 $ \soneto{X}{n} $，则 $ (\theta, X_1, \cdots, X_n) $ 的联合密度为
$$
h(\theta) f(X_1, \theta) \cdots f(X_n, \theta)
$$
由此算出 $(\soneto{X}{n})$ 的边缘密度为
$$
p(\soneto{X}{n}) = \int h(\theta) f(X_1, \theta) \cdots f(X_n, \theta) \dd\theta
$$
从而得出 $\theta$ 在给定 $\soneto{X}{n}$ 的条件密度为
$$
h(\theta \mid X_1, \cdots, X_n) = h(\theta) f(X_1, \theta) \cdots f(X_n, \theta) / p(X_1, \cdots, X_n)
$$

一般去上式的均值作为估计, 即
$$
\tilde{\theta} = E(h(\theta \mid \soneto{X}{n})).
$$

---

$h(\theta)$ 一般是概率函数，即满足 $ h(\theta) \ge 0,\, \dint h(\theta) \dd\theta = 1 $.

但对于积分域为无穷区间，或一些特定的分布，可以采用其它函数，比如 $ h(\theta) = 1 $，或直接取为<u>先验密度</u>等. 此时 $h(\theta)$ 称为 "广义先验密度".

---

根据 $n$ 次独立试验中事件 $A$ 发生的次数 $X$ 去估计其发生的概率 $p$，按照 "同等无知" 原则（贝叶斯原则），由上述方法积分得
$$
\tilde{p} = \dfrac{X+1}{n+2}.
$$

---

- 估计正态分布 $N(\mu, \sigma^2)$ 中的 $\mu$ 时，取 $h(\mu) = 1$；
- 估计正态分布 $N(\mu, \sigma^2)$ 中的 $\sigma$ 时，取 $ h(\sigma) = \sigma\inv $；
- 估计指数分布 $ E(\lambda) $ 中的 $\lambda$ 时，取$ h(\lambda) = \lambda\inv $.

---

由先验分布 $ N(\mu. \sigma^2) $ 估计正态总体 $ N(\theta, 1) $ 中的 $\theta$ 为（取 $h(\theta)$ 为先验密度）
$$
\tilde{\theta} = \dfrac{n}{n+\sigma^{-2}} \overline{X\,} + \dfrac{\sigma^{-2}}{n+\sigma^{-2}} \mu.
$$

## 4.3	点估计的优良性准则

估计的整体性能

1. 无偏性
   1. 没有系统性的偏差, 即误差的均值为零.
   2. 各次估计的均值依概率收敛至被估计值.
2. 有效性 (数量指标)
   1. 方差
   2. 均方误差

3. 相合性 (一致性)

### 4.3.1	估计量的无偏性

即无 **系统误差** $ E(\hat\theta) - \theta $. 故 **无偏估计量** $\hat{g}$ 须满足
$$
E_{\theta_1, \cdots, \theta_k} [\hat{g}(X_1, \cdots, X_n)] = g(\theta_1, \cdots, \theta_k).
$$

- $m = \overline{X}$ 是 $E(X)$ 的无偏估计.
- 如果总体均值未知, 则 $ S^2 = \insum\dfrac{(X_i-\overline{X})^2}{n-1} $ 是 $\Var(X)$ 的无偏估计.
- 如果总体均值已知, 则 $ m_2 = \nsum \dfrac{(X_i - \overline{X})^2}{n} $ 是 $\Var(X)$ 的无偏估计.
- 由 $ \sigma^2 = E(S^2) = \Var(S) + (ES)^2 $ 知, $S$ 总是 $\sigma$ 系统性偏低的估计.

---

设 $ \hat{g} = \hat{g}(\soneto{X}{n}) $ 是未知参数的函数 $ g(\soneto{\theta}{k}) $ 的一个估计量, 如果 $E(\hat\theta)$ 存在, 且
$$
\nlim E(\hat{g}(\soneto{X}{n})) = g(\soneto{\theta}{k})
$$
则称 $\hat g$ 为 $g$ 的 **渐进无偏估计量**.

- $ m_2 = \dfrac{1}{n} \insum (X_i - \overline{X})^2 $ 是 $\sigma^2$ 的渐进无偏估计量, 但不是无偏估计量.

---

- :star: (看思路) 对于正态分布总体 $N(\mu, \sigma^2)$, 由 $ (n-1)S^2 / \sigma^2 \sim \chi_{n-1}^2 $ 算出
  $$
  S/\sigma \sim g(s) = \begin{cases}
  	\dfrac{
  		(n-1)^{\tfrac{n-1}{2}}
  	}{
  		2^{\tfrac{n-3}{2}} \Gamma\pqty{\cfrac{n-1}{2}}
  	}, & s>0 \\
  	0 & s \le 0.
  \end{cases}
  $$
  计算 $E(S) = \sigma \intoi sg(s) \ds$, 故 $\sigma$ 的一个无偏估计是
  $$
  \tilde{\sigma} = 
  \sqrt{\dfrac{n-1}{2}} \dfrac{
  	\Gamma\pqty{\dfrac{n-1}{2}}
  }{
  	\Gamma\pqty{\dfrac{n}{2}}
  } S.
  $$

- <font color="red">无偏估计不一定好</font>, 比如 $X\sim P(\lambda)$, 则 $g(\lambda) = \e^{-2\lambda}$ 唯一的无偏估计为
  $$
  \hat g(X) = \begin{cases}
  	1, & X \text{ 为偶数}, \\
  	-1, & X \text{ 为奇数}.
  \end{cases}
  $$

### 4.3.2	最小方差无偏估计

#### 1	均方误差

$$
\begin{align}
M_{\hat{\theta}}(\theta) &= E_\theta \bqty{
	\hat{\theta}(X_1, \cdots, X_n) - \theta
}^2
\\
&= \Var_\theta(\hat{\theta}) + \bqty{
	E_\theta(\hat{\theta}) - \theta
}^2
\end{align}
$$

#### 2	最小方差无偏估计 (MVU 估计)

注意是最小方差, 而不是最小均方误差. (Minimum Variance Unbiased)

#### 3	克拉美 - 劳不等式

对于单参数情况 $f(x, \theta)$, 为估计 $g(\theta)$, 记 **费歇尔信息量** 为
$$
\begin{align}
I(\theta) &= E \bqty{\pqty{
	\left.
		\pdv{f(x, \theta)}{\theta}
	\right/ f(x, \theta)
}^2}
\\
&= \int \bqty{
	\left. \pqty{
		\pdv{f(x, \theta)}{\theta}
	}^2 \right/ f(x, \theta)
} \dx
& \text{(连续的总体分布)}
\\
&= \sum_{i} \left. \pqty{
	\pdv{f(a_i, \theta)}{\theta}
}^2 \right/ f(a_i, \theta)
& \text{(离散的总体分布)}
\end{align}
$$
则对任一无偏估计 $\hat{g} = \hat{g}(\soneto{X}{n})$, 有 **克拉美 - 劳不等式**:
$$
\Var_\theta(\hat{\theta}) \ge (g'(\theta))^2 / (nI(\theta)).
$$

- <font color="red">MVU 的均方误差不一定是最小的</font>, 如对于正态分布 $N(\mu, \sigma^2)$, 其中 $\mu$ 已知, 则 $m_2$ 是 MVU 估计, 但 $ E(m_2 - \sigma^2)^2 = \dfrac{2\sigma^4}{n} > E(\dfrac{m_2}{n+1} - \sigma^2)^2 = \dfrac{2\sigma^4}{n+1} $.
- 若 $\hat\theta_1$ 和 $\hat\theta_2$ 都是 $\theta$ 的 MVU 估计, 则 $ a\hat\theta_1 + b\hat\theta_2 + c $ 是 $(a+b)\theta + c$ 的 MVU 估计. :star: :star: (利用第三章定理 3.1, 2°)
- 若 $ E(X) = \theta,\, \insum c_i = 1 $, 则 $ \insum c_iX_i $ 是 $\theta$ 的无偏估计, 并且当且仅当 $ c_i = \dfrac{1}{n} $ 时, 其为 MVU 估计.

### 4.3.3	估计量的相合性与渐进正态性

#### 1	相合性

如果当样本大小 $n$ 无限增加时, 估计量 $T(\soneto{X}{n})$ 依概率收敛于被估计值, 则称该估计量是 **相合估计量**, 即
$$
\forall \ve>0: \nlim P_{\theta_1, \cdots, \theta_k} \pqty{
	\vqty{
		\hat{g}(X_1, \cdots, X_n) - g(\theta_1, \cdots, \theta_n)
	} \ge \ve
} = 0.
$$
具有相合性的例子: $ m(n),\, m_2(n) $, 绝大多数极大似然估计等等.

- 由[切比雪夫不等式](# 3.4.1	大数定理)知:
  $$
  0 \le \nlim P(\vqty{\hat{g} - g} \ge \ve) \le \dfrac{D(\hat{g})}{\ve^2}.
  $$

#### 2	渐进正态性

- 大样本性质
  - 相合性
  - 渐进正态性
- 小样本性质
  - 无偏性

## 4.4	区间估计

### 4.4.1	基本概念

**奈曼理论** 的原则: 先保证可靠度, 再提升精度.

称区间估计 $[\hat{\theta}_1, \hat{\theta}_2]$ 的 **置信系数** 为 $1-\alpha$, 如果
$$
\exist \alpha>0,\, \forall \theta:
P_\theta \pqty{
	\hat{\theta}_1 (X_1, \cdots, X_n) \le \theta \le
	\hat{\theta}_2 (X_1, \cdots, X_n)
} = 1-\alpha.
$$
称区间估计 $[\hat{\theta}_1, \hat{\theta}_2]$ 的 **置信水平** (**置信度**) 为 $1-\alpha$, 如果
$$
\exist \alpha>0,\, \forall \theta:
P_\theta \pqty{
	\hat{\theta}_1 (X_1, \cdots, X_n) \le \theta \le
	\hat{\theta}_2 (X_1, \cdots, X_n)
} \ge 1-\alpha.
$$

- 随机区间 $[\hat\theta_1, \hat\theta_2]$ 称为 **双侧置信区间**.
- $ (-\infty, \hat\theta_2] $ 和 $ [\hat\theta_1, +\infty) $ 称为 **单侧置信区间**.
- $\hat\theta_1$ 和 $\hat\theta_2$ 分别称为置信下界和置信上界.
- $\alpha$ 一般取为 0.1, 0.05, 0.01, 0.001.

---

区间估计的研究对象:

1. 置信系数或置信水平.
2. 区间长度.
3. 区间右端点与左端点之比.

### 4.4.2	枢轴变量法

上 $\beta$ 分位点: $F(v_\beta) = 1-\beta$.

下 $\beta$ 分位点: $F(w_\beta) = \beta$.

上 $\beta$ 分位点就是下 $1-\beta$ 分位点.

统计三大分布的上 $\beta$ 分位点记为: $ \chi_n^2(\beta),\, t_n(\beta),\, f_{n, m}(\beta) $.

---

利用上 $\beta$ 分位点 $w_\beta$ 寻找区间估计的 **枢轴变量法**:

1. 找一个与被估计参数 $g(\theta)$ 有关的统计量 $T$.
2. 找 **枢轴变量** $S(T, g(\theta))$, 使其<u>分布</u> $F$ 与 $\theta$ 无关.
3. $ a \le S(T, g(\theta)) \le b \QRLA A \le g(\theta) \le B $.
4. $ P(w_{1-\alpha/2} \le S(T, g(\theta)) \le w_{a/2}) = 1-\alpha $.

---

一样本 $t$ 区间估计, 为保证长度 $ 2S t_{n-1} (\alpha/2) / \sqrt{n} \le L $, 斯泰因提出了 **两阶段抽样** 的方法, 其中追加抽样的次数为
$$
m = \begin{cases}
	0, & n \le [4 t_{n-1}^2(\alpha/2) S^2 / L^2] + 1, \\
	n-1 - [4 t_{n-1}^2(\alpha/2) S^2 / L^2],
	& n \gt [4 t_{n-1}^2(\alpha/2) S^2 / L^2] + 1.
\end{cases}
$$
记两次样本全体的均值为 $\tilde{X}$, 则区间估计 $ [\tilde{X} - L/2,\, \tilde{X} + L/2] $ 有置信系数 $1-\alpha$.

### 4.4.3	大样本法

大样本区间估计: 利用 [中心极限定理](# 3.4.2	中心极限定理) 与枢轴变量法.

例如, 一般的, 设总体有均值 $\theta$, 方差 $\sigma^2$, 并且都位置, 从样本 $\soneto{X}{n}$ 做 $\theta$ 的区间估计. 由于样本均方差 $S$ 是 $\sigma$ 的祥和估计, 利用中心极限定理, 当 $n$ 足够大时, 有
$$
\sqrt{n} (\overline{X} - \theta) / S \sim N(0, 1).
$$
以此为枢轴变量, 于是有区间估计
$$
\bqty{
	\overline{X} - S u_{\alpha/2} / \sqrt{n},\,
	\overline{X} + S u_{\alpha/2} / \sqrt{n}
}.
$$

---

对于二项分布, 当 $\alpha = 0.05,\,n\ge40$ 时, 有区间长度 $\theta_2 - \theta_1 \le 0.3$.

### 4.4.4	置信界

置信系数 (水平) 为 $\alpha$ 的置信上界 $\overline{\theta}$ 和置信下界 $\underline{\theta}$:
$$
\begin{align}
& \forall \theta:
P_\theta (\overline{\theta}(\soneto{X}{n}) \ge \theta) = 1-\alpha
\\
& \forall \theta:
P_\theta (\underline{\theta}(\soneto{X}{n}) \le \theta) = 1-\alpha
\end{align}
$$

### 4.4.5	贝叶斯法

即寻找 $\hat\theta_1,\, \hat\theta_2$, 使得
$$
\begin{align}
& \int_{\hat\theta_1}^{\hat\theta_2} h(\theta \mid X_1, \cdots, X_n) \dd{\theta} = 1-\alpha
& \text{(区间估计)}
\\
& \int_{-\infty}^{\hat\theta} h(\theta \mid X_1, \cdots, X_n) \dd{\theta} = 1-\alpha
& \text{(置信上界)}
\\
& \int_{\hat\theta}^{+\infty} h(\theta \mid X_1, \cdots, X_n) \dd{\theta} = 1-\alpha
& \text{(置信下界)}
\end{align}
$$
区间估计中确定 $\theta_1,\, \theta_2$ 的方法 (原则):

1. 使 $\hat\theta_2 - \hat\theta_1$ 最小.
2. 使 $ \hat\theta_2 / \hat\theta_1 $ 最小.
3. 取置信水平为 $\alpha/2$ 的置信上下界.

### 常用区间估计表

<img src="E:\Notes\Math\概统\image\常用区间估计表.png">







# 第 5 章	假设检验

## 5.1	问题提法和基本概念

### 5.1.1	例子与问题提法

**原假设** (零假设, 解消假设) 是 $\R^n$ 的一个子集, 其中 $n$ 是未知参数的数量.

**对立假设** (备择假设) 是原假设补集的子集.

检验统计量, 接受域, 否定域 (临界域), 临界值.

简单假设, 复合假设. 赘余参数 (多余参数, 讨厌参数).

### 5.1.2	功效函数

设总体分布中包含未知参数 $\soneto{\theta}{k}$, $H_0$ 为原假设, $H_1$ 为对立假设, $\varPhi$ 是基于样本 $\soneto{X}{n}$ 而对 $H_0$ 做的一个检验, 则其 **功效函数** 是:
$$
\beta_\varPhi(\soneto{\theta}{n}) = P_{\soneto{\theta}{n}} (在检验\ \varPhi\ 之下,\, H_0\ 被否定)
$$

- 当 $ (\soneto{\theta}{n}) \in H_0 $ 时, 上式越小越好.
- 当 $ (\soneto{\theta}{n}) \in H_1 $ 时, 上式越大越好, 此时称为功效函数.

### 5.1.3	两类错误与假设检验思路

两类错误

1. $H_0$ 正确, 但被否定.
2. $H_0$ 错误, 但被接受.

$$
\begin{align}
\alpha_{1\varPhi} (\soneto{\theta}{k}) &= \begin{cases}
	\beta_{\varPhi} (\soneto{\theta}{k}),
	& (\soneto{\theta}{k}) \in H_0,
	\\
	0 & (\soneto{\theta}{k}) \in H_1.
\end{cases}
\\
\alpha_{2\varPhi} (\soneto{\theta}{k}) &= \begin{cases}
	0, & (\soneto{\theta}{k}) \in H_0,
	\\
	1 - \beta_{\varPhi} (\soneto{\theta}{k}),
	& (\soneto{\theta}{k}) \in H_1.
\end{cases}
\end{align}
$$

---

**奈曼-皮尔逊理论** 的思路: 先保证第一类错误的概率不超过某个定值 $\alpha$, 再使第二类错误的概率尽可能小.

### 5.1.4	检验水平与一致最优检验

$H_0$ 的一个水平为 $\alpha$ 的检验 $\varPhi$:
$$
\forall (\soneto{\theta}{k}) \in H_0:
\beta_\varPhi(\soneto{\theta}{k}) \le \alpha.
$$
并使 $\alpha$ 仅可能小. 即固定第一类错误概率的原则.

- 若 $\varPhi$ 是 $H_0$ 的一个水平为 $\alpha_0$ 的检验, 则它也是水平为 $ \alpha\ (\forall \alpha > \alpha_0) $ 的检验.

---

假设检验问题 $H_0:H_1$ 的一个水平为 $\alpha$ 的一致最优检验 $\varPhi$: 即对任何一个其它水平 $\alpha$ 的检验 $g$ 有
$$
\beta_\varPhi (\soneto{\theta}{k}) \ge \beta_g (\soneto{\theta}{k}) \quad (对任何\ (\soneto{\theta}{k}) \in H_1).
$$

- 在总体分布只依赖于一个参数 $\theta$, 而原假设 $H_0$ 是 $\theta \le \theta_0$ 或 $\theta \ge \theta_0$ 时, 一致最优检验存在.

## 5.2	重要参数检验

### 5.2.1	正态总体均值的检验

设 $\soneto{X}{n}$ 是从正态总体 $N(\theta, \sigma^2)$ 中抽出的样本.

原假设和对立假设分别为:

1. $ H_0: \theta \ge \theta_0,\, H_1: \theta \lt \theta_0 $.
2. $ H_0': \theta \le \theta_0,\, H'_1: \theta > \theta_0 $.
3. $ H''_0: \theta = \theta_0,\, H''_1: \theta \ne \theta_0 $.

#### 1	方差已知

- $ H_0: \theta \ge \theta_0,\, H_1: \theta \lt \theta_0 $.
  - $\varPhi:$ 当 $ \overline{X} \ge \theta_0 - \dfrac{\sigma u_\alpha}{\sqrt{n}} $ 时接受原假设 $H_0$, 否则否定 $H_0$.
  - 功效函数 $ \beta_\varPhi(\theta) = \varPhi\pqty{
    	\dfrac{\sqrt{n}}{\sigma} (\theta_0 - \theta) - u_\alpha
    } \ge 1 - \beta $.
  - 欲使第二类错误概率足够小: $ n \ge \dfrac{
    	\sigma^2 (u_\alpha + u_\beta)^2
    }{
    	(\theta_0 - \theta_1)^2
    } $.
- $ H_0': \theta \le \theta_0,\, H'_1: \theta > \theta_0 $.
  - $\varPhi:$ 当 $ \overline{X} \le \theta_0 + \dfrac{\sigma u_\alpha}{\sqrt{n}} $ 时接受原假设 $H'_0$, 否则否定 $H'_0$.
  - 功效函数 $ \beta'_\varPhi(\theta) = 1 - \varPhi\pqty{
    	\dfrac{\sqrt{n}}{\sigma} (\theta_0 - \theta) + u_\alpha
    } \ge 1 - \beta $.
  - 欲使第二类错误概率足够小: $ n \ge \dfrac{
    	\sigma^2 (u_\alpha + u_\beta)^2
    }{
    	(\theta_0 - \theta_1)^2
    } $.
- $ H''_0: \theta = \theta_0,\, H''_1: \theta \ne \theta_0 $.
  - $ \varPhi'': $ 当 $ \vqty{\overline{X} - \theta_0} \le \dfrac{\sigma u_{\alpha / 2}}{\sqrt n} $ 时接受 $H''_0$, 否则否定 $H''_0$.
  - 功效函数 $ \beta''_\varPhi(\theta) = 2 \varPhi\pqty{\dfrac{\sqrt{n}}{\sigma} (\theta_0 - \theta) - u_{\alpha / 2}} \ge 1 - \beta $.
  - 欲使第二类错误概率足够小: $ n \ge \dfrac{\sigma^2 (u_{\frac{\alpha}{2}} + u_{\frac{1+\beta}{2}})^2}{(\theta_0 - \theta_1)^2} $.

---

注

- 若 $ \theta_0 - \dfrac{\sigma u_\alpha}{\sqrt n} \le \overline{X} \le \theta_0 + \dfrac{\sigma u_\alpha}{\sqrt n} $, 则既接受 $H_0$, 也接受 $H_0'$.
- $\varPhi$ 和 $\varPhi'$ 都是一致最优检验.

- $\varPhi''$ 不是一致最优检验, 并且 $H_0''$ 不存在一致最优检验.

#### 2	方差未知











### 5.2.2	两个正态总体均值差的检验

### 5.2.3	正态分布方差的检验

### 5.2.4	指数分布参数的检验

### 5.2.5	二项分布参数的检验

### 5.2.6	泊松分布参数的检验

### 5.2.7	大样本检验

### 5.2.8	贝叶斯方法



5.3	拟合优度检验

5.3.1	理论分布完全已知且只取有限个值的情况

5.3.2	理论分布只含有限个值但不完全已知的情况

5.3.3	对列联表的应用

5.3.4	总体分布为一般分布的情况

