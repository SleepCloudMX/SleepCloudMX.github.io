<h1 align="center">数理统计</h1>

$$
% \text{眠云跂石整理}

% 字符
\renewcommand{\i}{\textup{i}}
\newcommand{\e}{\textup{e}}
\newcommand{\ve}{\varepsilon}
\newcommand{\Beta}{\mathrm{B}}
\newcommand{\SS}{\mathrm{SS}}

% 上下标
\newcommand{\trans}{^\mathrm{T}}
\newcommand{\inv}{^{-1}}
\newcommand{\adj}[1]{^{\pqty{#1^*}}}

% 特定内容
\newcommand{\oneton}{1,2,\cdots,n}
\newcommand{\oneto}[1]{1,2,\cdots,#1}

\newcommand{\ssto}[3]{#1_1 #3 #1_2 #3 \cdots #3 #1_{#2}}
\newcommand{\ssup}[3]{#1^1 #3 #1^2 #3 \cdots #3 #1^{#2}}
\newcommand{\soneto}[2]{\ssto{#1}{#2}{,}}
\newcommand{\splus}[2]{\ssto{#1}{#2}{+}}

\newcommand{\aqty}[1]{\expval{#1}}
\newcommand{\pbqty}[1]{\left(#1\right]}
\newcommand{\bpqty}[1]{\left[#1\right)}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}

\newcommand{\ccdots}{\cdot\cdots\cdot}

% 下面几个只是为了方便一点点而已
\newcommand{\dx}{\dd{x}}
\newcommand{\dy}{\dd{y}}
\newcommand{\dz}{\dd{z}}
\newcommand{\dt}{\dd{t}}
\newcommand{\ds}{\dd{s}}

% 如果只使用 \dd{x}\dd{y} 的话, 中间会有多余的间隔.
\newcommand{\ddd}[2]{\,\mathrm{d}#1\mathrm{d}#2}
\newcommand{\dxdy}{\,\mathrm{d}x\mathrm{d}y}
\newcommand{\dydz}{\,\mathrm{d}y\mathrm{d}z}
\newcommand{\dzdx}{\,\mathrm{d}z\mathrm{d}x}
\newcommand{\dudv}{\,\mathrm{d}u\mathrm{d}v}
\newcommand{\dxdydz}{\,\mathrm{d}x\mathrm{d}y\mathrm{d}z}

% 矩阵的宏指令
\newcommand{\pmcmn}[3]{\begin{pmatrix}
	#1_{11} & #1_{12} & \cdots & #1_{1#3} \\
	#1_{21} & #1_{22} & \cdots & #1_{n#3} \\
	\vdots & \vdots && \vdots \\
	#1_{#2 1} & #1_{#2 2} & \cdots & #2_{n#3} \\
\end{pmatrix}}

\newcommand{\pmc}[1]{\pmcmn{#1}{n}{n}}

\newcommand{\pvcn}[2]{\begin{pmatrix}
	#1_1 \\ #1_2 \\ \vdots \\ #1_{#2}
\end{pmatrix}}

\newcommand{\pvc}[1]{\pvcn{#1}{n}}

\newcommand{\pto}{\overset{P}{\to}}



% 函数名
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Corr}{Corr}

% 运算符
\newcommand{\dint}{\displaystyle\int}
\newcommand{\inti}{\dint_{-\infty}^{+\infty}}
\newcommand{\intoi}{\dint_0^{+\infty}}

\newcommand{\intl}{\displaystyle\int\limits}
\newcommand{\iintl}{\displaystyle\iint\limits}
\newcommand{\iiintl}{\displaystyle\iiint\limits}

\newcommand{\dsum}{\displaystyle\sum}
\newcommand{\nsum}{\dsum_{n=1}^\infty}
\newcommand{\nosum}{\dsum_{n=0}^\infty}
\newcommand{\insum}{\dsum_{i=1}^n}

\newcommand{\dprod}{\displaystyle\prod}
\newcommand{\nprod}{\dprod_{n=1}^\infty}

\newcommand{\xlim}{\lim\limits_{x\to x_0}}
\newcommand{\nlim}{\lim\limits_{n\to\infty}}
\newcommand{\clim}[1]{\lim\limits_{#1\to\infty}}
\newcommand{\ulim}{\overline\lim\limits_{n\to\infty}}
\newcommand{\dlim}{\underline\lim\limits_{n\to\infty}}
% 注意这里的 d 是 down, 而不是 displaystyle

% 缩写
\newcommand{\bm}[1]{\boldsymbol{#1}}
\newcommand{\LRA}{\Leftrightarrow}
\newcommand{\RLA}{\Leftrightarrow}
\newcommand{\LA}{\Leftarrow}
\newcommand{\RA}{\Rightarrow}

\newcommand{\lra}{\leftrightarrow}
\newcommand{\rla}{\leftrightarrow}
\newcommand{\la}{\leftarrow}
\newcommand{\ra}{\rightarrow}

\newcommand{\QRLA}{\quad\RLA\quad}
\newcommand{\QRA}{\quad\RA\quad}
\newcommand{\LLRA}{\Longleftrightarrow}

\newcommand{\QNRA}{\quad\nRightarrow\quad}
\newcommand{\qnra}{\quad\nrightarrow\quad}

% displaytsyle 的指令缩写
\newcommand{\ddv}{\displaystyle\dv}
\newcommand{\dpdv}{\displaystyle\pdv}
$$

[TOC]

# 第 4 章	参数估计

## 4.1	基本概念与性质

### 4.1.1	基本概念与常用统计图

**总体**（母体）是概率分布族的一员.

**总体分布**	离散性（概率函数），连续型（概率密度函数）

**单参数分布族**	

**非参数总体**	

**样本大小 (容量)**	

---

**常用统计图**

1. **频数分布表**

   | 组号 | 区间     | 频数 $n_i$ | 频率 $f_i$ |
   | ---- | -------- | ---------- | ---------- |
   | 1    | $(1, 2]$ | 2          | 0.40       |
   | 2    | $(2, 3]$ | 3          | 0.60       |
   | 合计 |          | 5          | 1.00       |

2. **频率直方图**	以 $ \dfrac{f_i}{\Delta t_i} $ 为高. 所有小矩形的面积和为 1.

3. **条形图**	一般用于小样本离散性随机变量总体分布.

---

### 4.1.2	经验分布函数与格列文科定理

**经验分布函数 (样本分布函数)**	$ F_n(x) = \Bqty{ \soneto{X}{n} \text{ 中不大于 $x$ 的个数} } / n $.

即将 $X$ 的样本值 $\soneto{x}{n}$ 从小到大重排后, 定义经验分布函数如下.
$$
\underbrace{x_{(1)}, \cdots, x_{(1)}}_{n_1},
\underbrace{x_{(2)}, \cdots, x_{(2)}}_{n_2}, \cdots
\underbrace{x_{(m)}, \cdots, x_{(m)}}_{n_m},

\\
F_n(x) = \begin{cases}
	0, & x < x_{(1)}, \\
	\dfrac{1}{n} \dsum_{i=1}^k n_i, & x_{(k)} \le x < x_{(k+1)} \\
	1, & x \ge x_{(m)}
\end{cases}
$$

1. $ 0 \le F_n(x) \le 1 $.
2. $F_n(x)$ 单调不减.
3. $ F_n(-\infty) = 0,\, F_n(+\infty) = 1 $.
4. $F_n(x)$ 右连续.

---

**格列文科定理**	对于任意实数 $x$, 经验分布函数 $F_n(x)$ 以概率 1 一致收敛于总体分布函数 $F(x)$, 即
$$
P\Bqty{
	\nlim \sup_{-\infty < x < +\infty}
	\vqty{F_n(x) - F(x)} = 0
} = 1.
$$

- 经验分布函数不确定, 不唯一, 所以在极限外套一个 P.

---

### 4.1.3	常用统计量及其性质

**统计量**	只依赖于样本，而不依赖于其未知参数.

- 样本的统计量为 $ g(\soneto{X}{n}) $.
- 统计量的观测值为 $g(\soneto{x}{n})$.

**样本均值**	$ \overline{X} = a_1 = \dfrac{1}{n} \insum{X_i} $.

- 其观测值记为 $ \overline{x} = \dfrac{1}{n} \insum x_i $.

- 对于一般分布 :star:

  - $ E(\overline{X}) = \mu $.
  - $ E\pqty{\overline{X}^2} = \dfrac{\sigma^2}{n} + \mu^2 $.
  - $ E\pqty{\overline{X}^3} = \dfrac{\mu_3}{n^2} + \dfrac{3}{n} \mu\sigma^2 + \mu^3 $.
  - $ E\pqty{\overline{X}^4} = \dfrac{\mu_4}{n^3} + \dfrac{4}{n^2} \mu_3 \mu + \dfrac{18}{n} \mu^2 \sigma^2 + 7\mu^4 $.
  - $ E\pqty{X_i^2\overline{X}} = \dfrac{\mu_3}{n} + \dfrac{n-1}{n} (\sigma^2 + \mu^2) \mu $.
  - $ E\pqty{X_i \overline{X}^{k-1}} = E\pqty{\overline{X}^k} $.
  - $ D(\overline{X}) = \dfrac{\sigma^2}{n} $.
  - $ \mu_k(\overline{X}) = E\bqty{\insum\pqty{X_i - \overline{X}}^k} = \dfrac{\mu_k}{n^{k-1}} $.

- :star: 设总体有 $N$ 个数据 $ \soneto{a}{N} $, 均值为 $ \mu = \dfrac{1}{N} \dsum_{i=1}^N a_i $, 方差为 $ \sigma^2 = \dfrac{1}{N} \dsum_{i=1}^N (a_i - \mu)^2 $.

  从总体中抽取 $n$ 个值 $ \soneto{X}{n} $ 作为样本, 则

  - $ E(\overline{X}) = \mu $.
  - $ D(\overline{X}) = \dfrac{N-n}{N-1} \dfrac{\sigma^2}{n} $.

  当 $ N \to +\infty $ 时, 即抽取的样本相互独立时, 有 $ D(\overline{X}) \sim \dfrac{\sigma^2}{n} $.

**样本离差平方和**	$ \mathrm{SS} = \insum (X_i - \overline{X})^2 = \insum X_i^2 - n \overline{X}^2 $.

- 其观测值记为 $ \mathrm{ss} = \insum (x_i - \overline{x})^2 = \insum x_i^2 - n \overline{x}^2 $.

**样本方差**	$ S^2 = \dfrac{1}{n-1} \dsum_{i=1}^n (X_i - \overline{X})^2 $.

- 其观测值记为 $ s^2 $.
- 标准差又称<u>均方差</u>, 样本标准差的观测值记为 $s$.
- 对于一般分布, 有
  - $ E(S^2) = \sigma^2 $.
  - $ D(S^2) = \dfrac{1}{n} \pqty{\mu_4 - \dfrac{n-3}{n-1} \sigma^4} $. :star:$ %https://zhuanlan.zhihu.com/p/268376613 $
  - $ \Cov(\overline{X}, S^2) = \dfrac{\mu_3}{n} % - \dfrac{3\sigma^3 + \mu^2}{n-1} \mu $. :star: $ %https://zhuanlan.zhihu.com/p/535615384 $

- 对于正态分布, 有
  - $ D(S^2) = D\pqty{\dfrac{\sigma^2}{n-1} \chi_{n-1}^2} = \dfrac{2\sigma^4}{n-1} $. :star:
  - $ \Cov(\overline X, S^2) = 0 $.

**样本原点矩**	$ a_k = \dfrac{1}{n} \insum X_i^k $.

- 或使用 $A_k$ 表示样本原点矩, 用 $a_k$ 表示其观测值.

**样本中心矩**	$ m_k = \dfrac{1}{n} \displaystyle \sum_{i=1}^n (X_i - \overline{X})^k $.

- 或使用 $B_k$ 表示样本中心距, 用 $b_k$ 表示其观测值.
- 矩称为<u>理论矩</u>，样本矩称为<u>经验矩</u>，即经验分布函数的矩.
- $ m_2 = \dfrac{n-1}{n} S^2 $.
- $ E(m_3) = \pqty{1 - \dfrac{4}{n} + \dfrac{2}{n^2}} \mu_3 + \dfrac{9 -3n}{n} \mu\sigma^2 + \dfrac{3-n}{n}\mu^3 $.

**不知道叫什么的统计量**	$ \insum (X_i - \mu)^2 = \mathrm{SS} + n(\overline{X} - \mu)^2 $.

**样本协方差**	$ S_{XY} = \dfrac{1}{n-1} \insum (X_i - \overline{X}) (Y_i - \overline{Y}) $.

- 其观测值记为 $s_{_{XY}}$.

- 样本协方差是总体协方差的无偏估计 (可以是有限总体的不放回抽取)

  $ E(S_{XY}) = \Cov(X, Y) $.

**样本相关系数**	$ \rho_{XY} = \dfrac{S_{XY}}{S_X S_Y} $.

- 其中 $S_{X}$ 和 $S_{Y}$ 为样本均方差. 其观测值为 $ \rho_{XY} = \dfrac{s_{_{XY}}}{s_{_X} s_{_Y}} $.

---

样本的 **众数** 记为 $M_0$.

**次序统计量**	$ X_{(1)} \le X_{(2)} \le \cdots \le X_{(n)} $.

**样本中位数**	$ \hat{m} = M_e = \begin{cases} X_{((n+1)/2)}, & n \text{ 为奇数,} \\ (X_{(n/2)} + X_{(n/2+1)}) / 2, & n \text{ 为偶数.} \end{cases} $ 

---

**偏态系数**

- 计算公式
  - 简单偏态系数 $ \mathrm{SK} = \dfrac{m_3}{\sigma^3} = \dfrac{\sum(X - \overline{X})^3}{\sigma^3 \cdot N} $.
  - 加权偏态系数 $ \mathrm{SK} = \dfrac{\sum (X - \overline{X})^3 F}{\sigma^3 \sum F} $.
- 取值说明
  - $\mathrm{SK} = 0$ 表示数据为完全的对称分布.
  - $ \mathrm{SK} > 0 $ 表示数据为 **正偏态** (或 **右偏态**).
  - $ \mathrm{SK} < 0 $ 表示数据为 **负偏态** (或 **左偏态**).

### 4.3.4	正态总体常用统计量

设 $\soneto{X}{n}$ 与 $\soneto{Y}{n}$ 分别是来自正态总体 $ N(\mu_1, \sigma_1^2) = N(\mu, \sigma^2) $ 和 $ N(\mu_2, \sigma_2^2) $ 的相互独立的两个样本, 则

- 样本均值

  - $ \overline{X} \sim N\pqty{\mu, \dfrac{\sigma^2}{n}} $.
  - $ \dfrac{\overline{X} - \mu}{\sigma / \sqrt n} \sim N(0, 1) $.
  - $ \insum \pqty{\dfrac{X_i - \mu}{\sigma}}^2 \sim \chi_n^2 $.

- 样本方差

  - $ \dfrac{(n-1)S^2}{\sigma^2} \sim \chi_{n-1}^2 $.
  - $\overline{X}$ 与 $S^2$ 相互独立.
  - $ \dfrac{\overline{X} - \mu}{S / \sqrt n} \sim t_{n-1} $.

- 两组样本

  - $ \overline{X} - \overline{Y} \sim N\pqty{\mu_1 - \mu_2, \dfrac{\sigma_1^2}{n_1} + \dfrac{\sigma_2^2}{n_2}} $.

  - $ \dfrac{S_1^2 / S_2^2}{\sigma_1^2 / \sigma_2^2} \sim f_{n_1 - 1, n_2 - 1} $.

  - 当 $ \sigma_1^2 = \sigma_2^2 = \sigma^2 $, 令 $ S_\omega^2 = \dfrac{\mathrm{SS}_1^2 + \mathrm{SS}_2^2}{n_1 + n_2 - 2} $, 则
    $$
    \dfrac{
    	(\overline{X} - \overline{Y}) - (\mu_1 - \mu_2)
    }{
    	S_\omega \sqrt{
    		\dfrac{1}{n_1} + \dfrac{1}{n_2}
    	}
    } \sim t_{n_1 + n_2 - 2}.
    $$

---

:star: 设有 $m$ 个方差均为 $\sigma^2$ 的分布, 其中有 $k$ 个分布的期望未知. 从这些分布中任取 $n$ 个相互独立的样本数据, 则样本方差的一个无偏估计是 $ S^2 = \dfrac{\mathrm{SS}}{n - k} $. 若这些分布都是正态分布, 则进一步有 $ \dfrac{\mathrm{SS}}{\sigma^2} \sim \chi_{n-k}^2 $.

## 4.2	点估计

### 4.2.1	矩估计法

$$
\alpha_m = \inti x^m f(x; \theta_1, \cdots, \theta_2) \dd{x}
\approx a_m = \sum_{i=1}^n \dfrac{X_i^m}{n}.
$$

取 $ m = \oneto{k} $，联立方程组即得 $ \theta_i \approx \hat{\theta}_i(X_1, \cdots, X_n) $.

- $ \hat\theta_i(\soneto{X}{n}) $ 称为矩估计量.
- $ \hat\theta_i(\soneto{x}{n}) $ 称为矩估计值. (其它估计相关名称类似)

**变异系数**	$ \sigma/\mu $.

---

:crescent_moon: 对于任意均值 $\mu$ 与方差 $\sigma^2$ 存在的总体, 有矩估计:
$$
\begin{cases}
	\mu = \dfrac{1}{n} \insum X_i \\
	\sigma^2 + \mu^2 = \dfrac{1}{n} \insum X_i^2 \\
\end{cases}
\QRA
\begin{cases}
	\hat\mu = \overline{X} \\
	\hat{\sigma^2} = \dfrac{\SS}{n} \\
\end{cases}
$$

### 4.2.2	极大似然估计法

样本 $(\soneto{X}{n})$ 的总体分布函数 (样本似然函数) 为
$$
\begin{align}
L(x_1, \cdots, x_n,; \theta_1, \cdots, \theta_k)
&= \prod_{i=1}^n f(x_i; \soneto{\theta}{n})
% f(x_1; \theta_1, \cdots, \theta_k) f(x_2; \theta_1, \cdots, \theta_k) \cdots f(x_n; \theta_1, \cdots, \theta_k)
\\
L(X_1, \cdots, X_n; \theta_1^*, \cdots, \theta_k^*)
&= 
\max_{\theta_1, \cdots, \theta_k} L(X_1, \cdots, X_n; \theta_1, \cdots, \theta_k)
\end{align}
$$
欲得到极大似然估计，解如下似然方程组
$$
\pdv{\ln{L}}{\theta_i} = 0\quad (i = \oneto{k})
$$

### 4.2.3	贝叶斯估计法

先验分布，先验概率. 允许使用主观概率.

设总体有概率密度 $f(X, \theta)$，抽样本 $ \soneto{X}{n} $，则 $ (\theta, X_1, \cdots, X_n) $ 的联合密度为
$$
h(\theta) f(X_1, \theta) \cdots f(X_n, \theta)
$$
由此算出 $(\soneto{X}{n})$ 的边缘密度为
$$
p(\soneto{X}{n}) = \int h(\theta) f(X_1, \theta) \cdots f(X_n, \theta) \dd\theta
$$
从而得出 $\theta$ 在给定 $\soneto{X}{n}$ 的条件密度为
$$
h(\theta \mid X_1, \cdots, X_n) = h(\theta) f(X_1, \theta) \cdots f(X_n, \theta) / p(X_1, \cdots, X_n)
$$

一般取上式的均值作为估计, 即
$$
\tilde{\theta} = E(h(\theta \mid \soneto{X}{n})).
$$

---

$h(\theta)$ 一般是概率函数，即满足 $ h(\theta) \ge 0,\, \dint h(\theta) \dd\theta = 1 $.

但对于积分域为无穷区间，或一些特定的分布，可以采用其它函数，比如 $ h(\theta) = 1 $，或直接取为<u>先验密度</u>等. 此时 $h(\theta)$ 称为 "广义先验密度".

---

根据 $n$ 次独立试验中事件 $A$ 发生的次数 $X$ 去估计其发生的概率 $p$，按照 "同等无知" 原则（贝叶斯原则），由上述方法积分得
$$
\tilde{p} = \dfrac{X+1}{n+2}.
$$

---

- 估计正态分布 $N(\mu, \sigma^2)$ 中的 $\mu$ 时，取 $h(\mu) = 1$；
- 估计正态分布 $N(\mu, \sigma^2)$ 中的 $\sigma$ 时，取 $ h(\sigma) = \sigma\inv $；
- 估计指数分布 $ E(\lambda) $ 中的 $\lambda$ 时，取$ h(\lambda) = \lambda\inv $.

---

由先验分布 $ N(\mu. \sigma^2) $ 估计正态总体 $ N(\theta, 1) $ 中的 $\theta$ 为（取 $h(\theta)$ 为先验密度）
$$
\tilde{\theta} = \dfrac{n}{n+\sigma^{-2}} \overline{X\,} + \dfrac{\sigma^{-2}}{n+\sigma^{-2}} \mu.
$$

## 4.3	点估计的优良性准则

1. 小样本性质
   1. 无偏性: <u>误差期望</u>为零.
   2. 渐进无偏性: <u>误差期望</u>依概率收敛至零.
2. 有效性 (数量指标)
   1. 最小均方误差估计
   2. 最小方差无偏估计 (MVU)

3. 大样本性质
   1. 相合性 (一致性): <u>误差</u>依概率收敛至零.
   2. 渐进正态性: <u>自身分布</u>趋于正态分布


### 4.3.1	估计量的无偏性

无偏性即无系统误差 $ E(\hat\theta) - \theta $. 故 **无偏估计量** $\hat{g}$ 须满足
$$
E_{\theta_1, \cdots, \theta_k} [\hat{g}(X_1, \cdots, X_n)] = g(\theta_1, \cdots, \theta_k).
$$

- $m = \overline{X}$ 是 $E(X)$ 的无偏估计.
- 如果总体均值未知, 则 $ S^2 = \insum\dfrac{(X_i-\overline{X})^2}{n-1} $ 是 $\Var(X)$ 的无偏估计.
- 如果总体均值已知, 则 $ \nsum \dfrac{(X_i - \mu)^2}{n} $ 是 $\Var(X)$ 的无偏估计.
- 由 $ \sigma^2 = E(S^2) = \Var(S) + (ES)^2 $ 知, $S$ 总是 $\sigma$ 系统性偏低的估计. :crescent_moon: 

---

设 $ \hat{g} = \hat{g}(\soneto{X}{n}) $ 是未知参数的函数 $ g(\soneto{\theta}{k}) $ 的一个估计量, 如果 $E(\hat\theta)$ 存在, 且
$$
\nlim E(\hat{g}(\soneto{X}{n})) = g(\soneto{\theta}{k})
$$
则称 $\hat g$ 为 $g$ 的 **渐进无偏估计量**.

- $ m_2 = \dfrac{1}{n} \insum (X_i - \overline{X})^2 $ 是 $\sigma^2$ 的渐进无偏估计量, 但不是无偏估计量.

---

- :star: 对于正态分布总体 $N(\mu, \sigma^2)$, 由 $ (n-1)S^2 / \sigma^2 \sim \chi_{n-1}^2 $ 算出
  $$
  S/\sigma \sim g(s) = \begin{cases}
  	\dfrac{
  		(n-1)^{\tfrac{n-1}{2}}
  	}{
  		2^{\tfrac{n-3}{2}} \Gamma\pqty{\cfrac{n-1}{2}}
  	} \e^{-\tfrac{n-1}{2}s^2} s^{n-2}
  	, & s>0 \\
  	0 & s \le 0.
  \end{cases}
  $$
  计算 $E(S) = \sigma \intoi sg(s) \ds$, 故 $\sigma$ 的一个无偏估计是
  $$
  \tilde{\sigma} = 
  \sqrt{\dfrac{n-1}{2}} \dfrac{
  	\Gamma\pqty{\dfrac{n-1}{2}}
  }{
  	\Gamma\pqty{\dfrac{n}{2}}
  } S.
  $$
  
- <font color="red">无偏估计不一定好</font>, 比如 $X\sim P(\lambda)$, 则 $g(\lambda) = \e^{-2\lambda}$ 唯一的无偏估计为
  $$
  \hat g(X) = \begin{cases}
  	1, & X \text{ 为偶数}, \\
  	-1, & X \text{ 为奇数}.
  \end{cases}
  $$

### 4.3.2	最小方差无偏估计

#### 1	最小均方误差估计

$$
\begin{align}
M_{\hat{\theta}}(\theta) &= E_\theta \bqty{
	\hat{\theta}(X_1, \cdots, X_n) - \theta
}^2
\\
&= \Var_\theta(\hat{\theta}) + \bqty{
	E_\theta(\hat{\theta}) - \theta
}^2
\end{align}
$$

当 $ \hat \theta $ 是无偏估计量时, $ M_{\hat\theta}(\theta) = \Var_\theta(\hat\theta) $.

#### 2	最小方差无偏估计 (MVU 估计)

Minimum Variance Unbiased.

无偏估计中的最小方差，其均方误差不一定最小.

#### 3	克拉美 - 劳不等式

对于单参数情况 $f(x, \theta)$, 为估计 $g(\theta)$, 记 **费歇尔信息量** 为
$$
\begin{align}
I(\theta) &= E \bqty{\pqty{
	\left.
		\pdv{f(x, \theta)}{\theta}
	\right/ f(x, \theta)
}^2}
\\
&= \int \bqty{
	\left. \pqty{
		\pdv{f(x, \theta)}{\theta}
	}^2 \right/ f(x, \theta)
} \dx
& \text{(连续的总体分布)}
\\
&= \sum_{i} \left. \pqty{
	\pdv{f(a_i, \theta)}{\theta}
}^2 \right/ f(a_i, \theta)
& \text{(离散的总体分布)}
\end{align}
$$
则对任一无偏估计 $\hat{g} = \hat{g}(\soneto{X}{n})$, 有 **克拉美 - 劳不等式**:
$$
\Var_\theta(\hat{\theta}) \ge
\dfrac{g'(\theta)^2}{n I(\theta)}.
%(g'(\theta))^2 / (nI(\theta)).
$$

- <font color="red">MVU 的均方误差不一定是最小的</font>, 如对于正态分布 $N(\mu, \sigma^2)$, 其中 $\mu$ 已知, 则 $S^2$ 是 MVU 估计, 但 $ E(S_2 - \sigma^2)^2 = \dfrac{2\sigma^4}{n} > E(\dfrac{n-1}{n+1} S^2 - \sigma^2)^2 = \dfrac{2\sigma^4}{n+1} $.
- 若 $\hat\theta_1$ 和 $\hat\theta_2$ 都是 $\theta$ 的 MVU 估计, 则 $ a\hat\theta_1 + b\hat\theta_2 + c $ 是 $(a+b)\theta + c$ 的 MVU 估计. :star: :star: (利用第三章定理 3.1, 2°)
- 若 $ E(X) = \theta,\, \insum c_i = 1 $, 则 $ \insum c_iX_i $ 是 $\theta$ 的无偏估计, 并且当且仅当 $ c_i = \dfrac{1}{n} $ 时, 其为 MVU 估计.

### 4.3.3	估计量的相合性与渐进正态性

#### 1	相合性

如果当样本大小 $n$ 无限增加时, 估计量 $T(\soneto{X}{n})$ 依概率收敛于被估计值, 则称该估计量是 **相合估计量**, 即
$$
\forall \ve>0: \nlim P_{\theta_1, \cdots, \theta_k} \pqty{
	\vqty{
		\hat{g}(X_1, \cdots, X_n) - g(\theta_1, \cdots, \theta_n)
	} \ge \ve
} = 0.
$$
---

具有相合性的例子

- 所有的矩估计量.
- 绝大多数极大似然估计.

---

对于 $ g $ 的无偏估计 $ \hat g $, 由[切比雪夫不等式](# 3.4.1	大数定理)知:
$$
0 \le \nlim P(\vqty{\hat{g} - g} \ge \ve) \le \dfrac{D(\hat{g})}{\ve^2}.
$$
若 $ \nlim D(\hat g) = 0 $, 则其为相合估计量. :star: 

#### 2	渐进正态性

参考这篇高等数理统计的[文章](https://zhuanlan.zhihu.com/p/100643664).

## 4.4	区间估计

### 4.4.1	基本概念

**奈曼理论** 的原则: 先保证可靠度, 再提升精度.

称区间估计 $[\hat{\theta}_1, \hat{\theta}_2]$ 的 **置信系数** 为 $1-\alpha$, 如果
$$
\exist \alpha>0,\, \forall \theta:
P_\theta \pqty{
	\hat{\theta}_1 (X_1, \cdots, X_n) \le \theta \le
	\hat{\theta}_2 (X_1, \cdots, X_n)
} = 1-\alpha.
$$
称区间估计 $[\hat{\theta}_1, \hat{\theta}_2]$ 的 **置信水平** (**置信度**) 为 $1-\alpha$, 如果
$$
\exist \alpha>0,\, \forall \theta:
P_\theta \pqty{
	\hat{\theta}_1 (X_1, \cdots, X_n) \le \theta \le
	\hat{\theta}_2 (X_1, \cdots, X_n)
} \ge 1-\alpha.
$$

- 随机区间 $[\hat\theta_1, \hat\theta_2]$ 称为 **双侧置信区间**.
- $ (-\infty, \hat\theta_2] $ 和 $ [\hat\theta_1, +\infty) $ 称为 **单侧置信区间**.
- $\hat\theta_1$ 和 $\hat\theta_2$ 分别称为置信下界和置信上界.
- $\alpha$ 一般取为 0.1, 0.05, 0.025, 0.01, 0.001.

---

区间估计的研究对象:

1. 置信系数或置信水平.
2. 区间长度.
3. 区间右端点与左端点之比.

### 4.4.2	枢轴变量法

上 $\beta$ 分位点: $F(v_\beta) = 1-\beta$.

下 $\beta$ 分位点: $F(w_\beta) = \beta$.

上 $\beta$ 分位点就是下 $1-\beta$ 分位点.

统计三大分布的上 $\beta$ 分位点记为: $ \chi_n^2(\beta),\, t_n(\beta),\, f_{n, m}(\beta) $.

---

利用上 $\beta$ 分位点 $w_\beta$ 寻找区间估计的 **枢轴变量法**:

1. 找一个与被估计参数 $g(\theta)$ 有关的统计量 $T$.
2. 找 **枢轴变量** $S(T, g(\theta))$, 使其<u>分布</u> $F$ 与 $\theta$ 无关.
3. $ a \le S(T, g(\theta)) \le b \QRLA A \le g(\theta) \le B $.
4. $ P(w_{1-\alpha/2} \le S(T, g(\theta)) \le w_{a/2}) = 1-\alpha $.

---

一样本 $t$ 区间估计, 为保证长度 $ 2S t_{n-1} (\alpha/2) / \sqrt{n} \le L $, 斯泰因提出了 **两阶段抽样** 的方法, 其中追加抽样的次数为
$$
m = \begin{cases}
	0, & n \le [4 t_{n-1}^2(\alpha/2) S^2 / L^2] + 1, \\
	n-1 - [4 t_{n-1}^2(\alpha/2) S^2 / L^2],
	& n \gt [4 t_{n-1}^2(\alpha/2) S^2 / L^2] + 1.
\end{cases}
$$
记两次样本全体的均值为 $\tilde{X}$, 则区间估计 $ [\tilde{X} - L/2,\, \tilde{X} + L/2] $ 有置信系数 $1-\alpha$.

### 4.4.3	大样本法

大样本区间估计: 利用 [中心极限定理](# 3.4.2	中心极限定理) 与枢轴变量法.

例如, 一般的, 设总体有均值 $\theta$, 方差 $\sigma^2$, 并且都位置, 从样本 $\soneto{X}{n}$ 做 $\theta$ 的区间估计. 由于样本均方差 $S$ 是 $\sigma$ 的祥和估计, 利用中心极限定理, 当 $n$ 足够大时, 有
$$
\sqrt{n} (\overline{X} - \theta) / S \sim N(0, 1).
$$
以此为枢轴变量, 于是有区间估计
$$
\bqty{
	\overline{X} - S u_{\alpha/2} / \sqrt{n},\,
	\overline{X} + S u_{\alpha/2} / \sqrt{n}
}.
$$

---

对于二项分布, 当 $\alpha = 0.05,\,n\ge40$ 时, 有区间长度 $\theta_2 - \theta_1 \le 0.3$.

### 4.4.4	置信界

置信系数 (水平) 为 $\alpha$ 的置信上界 $\overline{\theta}$ 和置信下界 $\underline{\theta}$:
$$
\begin{align}
& \forall \theta:
P_\theta (\overline{\theta}(\soneto{X}{n}) \ge \theta) = 1-\alpha
\\
& \forall \theta:
P_\theta (\underline{\theta}(\soneto{X}{n}) \le \theta) = 1-\alpha
\end{align}
$$

### 4.4.5	贝叶斯法

即寻找 $\hat\theta_1,\, \hat\theta_2$, 使得
$$
\begin{align}
& \int_{\hat\theta_1}^{\hat\theta_2} h(\theta \mid X_1, \cdots, X_n) \dd{\theta} = 1-\alpha
& \text{(区间估计)}
\\
& \int_{-\infty}^{\hat\theta} h(\theta \mid X_1, \cdots, X_n) \dd{\theta} = 1-\alpha
& \text{(置信上界)}
\\
& \int_{\hat\theta}^{+\infty} h(\theta \mid X_1, \cdots, X_n) \dd{\theta} = 1-\alpha
& \text{(置信下界)}
\end{align}
$$
区间估计中确定 $\theta_1,\, \theta_2$ 的方法 (原则):

1. 使 $\hat\theta_2 - \hat\theta_1$ 最小.
2. 使 $ \hat\theta_2 / \hat\theta_1 $ 最小.
3. 取置信水平为 $\alpha/2$ 的置信上下界.

### 常用区间估计表

<img src="image\常用区间估计表 1.png">

<img src='image\常用区间估计表 2.png'>





# 第 5 章	假设检验

## 5.1	问题提法和基本概念

### 5.1.1	例子与问题提法

**原假设** (零假设, 解消假设) 是 $\R^n$ 的一个子集, 其中 $n$ 是未知参数的数量.

**对立假设** (备择假设) 是原假设补集的子集.

检验统计量, 接受域, 否定域 (临界域), 临界值.

简单假设, 复合假设. 赘余参数 (多余参数, 讨厌参数).

双边 (右边, 左边) 备择假设, 双边 (单边) 检验.

### 5.1.2	功效函数

设总体分布中包含未知参数 $\soneto{\theta}{k}$, $H_0$ 为原假设, $H_1$ 为对立假设, $\varPhi$ 是基于样本 $\soneto{X}{n}$ 而对 $H_0$ 做的一个检验, 则其 **功效函数** 是:
$$
\beta_\varPhi(\soneto{\theta}{n}) = P_{\soneto{\theta}{n}} (在检验\ \varPhi\ 之下,\, H_0\ 被否定)
$$

- 当 $ (\soneto{\theta}{n}) \in H_0 $ 时, 上式越小越好.
- 当 $ (\soneto{\theta}{n}) \in H_1 $ 时, 上式越大越好, 此时称为功效函数.

### 5.1.3	两类错误与假设检验思路

两类错误

1. 拒真: $H_0$ 正确, 但被否定.
2. 取伪: $H_0$ 错误, 但被接受.

$$
\begin{align}
\alpha_{1\varPhi} (\soneto{\theta}{k}) &= \begin{cases}
	\beta_{\varPhi} (\soneto{\theta}{k}),
	& (\soneto{\theta}{k}) \in H_0,
	\\
	0 & (\soneto{\theta}{k}) \in H_1.
\end{cases}
\\
\alpha_{2\varPhi} (\soneto{\theta}{k}) &= \begin{cases}
	0, & (\soneto{\theta}{k}) \in H_0,
	\\
	1 - \beta_{\varPhi} (\soneto{\theta}{k}),
	& (\soneto{\theta}{k}) \in H_1.
\end{cases}
\end{align}
$$

---

**奈曼-皮尔逊理论** 的思路: 先保证第一类错误的概率不超过某个定值 $\alpha$, 再使第二类错误的概率尽可能小.

### 5.1.4	检验水平与一致最优检验

$H_0$ 的一个水平为 $\alpha$ 的检验 $\varPhi$:
$$
\forall (\soneto{\theta}{k}) \in H_0:
\beta_\varPhi(\soneto{\theta}{k}) \le \alpha.
$$
并使 $\alpha$ 尽可能小. 即固定第一类错误概率的原则.

- 若 $\varPhi$ 是 $H_0$ 的一个水平为 $\alpha_0$ 的检验, 则它也是水平为 $ \alpha\ (\forall \alpha > \alpha_0) $ 的检验.

---

假设检验问题 $H_0:H_1$ 的一个水平为 $\alpha$ 的一致最优检验 $\varPhi$: 即对任何一个其它水平 $\alpha$ 的检验 $g$ 有
$$
\beta_\varPhi (\soneto{\theta}{k}) \ge \beta_g (\soneto{\theta}{k}) \quad (对任何\ (\soneto{\theta}{k}) \in H_1).
$$

- 在总体分布只依赖于一个参数 $\theta$, 而原假设 $H_0$ 是 $\theta \le \theta_0$ 或 $\theta \ge \theta_0$ 时, 一致最优检验存在.

## 5.2	重要参数检验

### 5.2.1	正态总体均值的检验

设 $\soneto{X}{n}$ 是从正态总体 $N(\mu, \sigma^2)$ 中抽出的样本.

原假设和对立假设分别为:

1. $ H_0: \mu \ge \mu_0,\, H_1: \mu \lt \mu_0 $.
2. $ H_0': \mu \le \mu_0,\, H'_1: \mu > \mu_0 $.
3. $ H''_0: \mu = \mu_0,\, H''_1: \mu \ne \mu_0 $.

#### 1	方差已知

利用 $ \dfrac{\overline{X} - \mu}{\sigma / \sqrt n} \sim N(0, 1) $.

- $ H_0: \mu \ge \mu_0,\, H_1: \mu \lt \mu_0 $.
  - $\varPhi:$ 当 $ \overline{X} \ge \mu_0 - \dfrac{\sigma u_\alpha}{\sqrt{n}} $ 时接受原假设 $H_0$, 否则否定 $H_0$.
  - 功效函数 $ \beta_\varPhi(\mu) = \varPhi\pqty{
    	\dfrac{\sqrt{n}}{\sigma} (\mu_0 - \mu) - u_\alpha
    } \ge 1 - \beta $.
  - 欲使第二类错误概率足够小: $ n \ge \dfrac{
    	\sigma^2 (u_\alpha + u_\beta)^2
    }{
    	(\mu_0 - \mu_1)^2
    } $.
- $ H_0': \mu \le \mu_0,\, H'_1: \mu > \mu_0 $.
  - $\varPhi:$ 当 $ \overline{X} \le \mu_0 + \dfrac{\sigma u_\alpha}{\sqrt{n}} $ 时接受原假设 $H'_0$, 否则否定 $H'_0$.
  - 功效函数 $ \beta'_\varPhi(\mu) = 1 - \varPhi\pqty{
    	\dfrac{\sqrt{n}}{\sigma} (\mu_0 - \mu) + u_\alpha
    } \ge 1 - \beta $.
  - 欲使第二类错误概率足够小: $ n \ge \dfrac{
    	\sigma^2 (u_\alpha + u_\beta)^2
    }{
    	(\mu_0 - \mu_1)^2
    } $.
- $ H''_0: \mu = \mu_0,\, H''_1: \mu \ne \mu_0 $.
  - $ \varPhi'': $ 当 $ \vqty{\overline{X} - \mu_0} \le \dfrac{\sigma u_{\alpha / 2}}{\sqrt n} $ 时接受 $H''_0$, 否则否定 $H''_0$.
  - 功效函数 $ \beta''_\varPhi(\mu) = 2 \varPhi\pqty{\dfrac{\sqrt{n}}{\sigma} (\mu_0 - \mu) - u_{\alpha / 2}} \ge 1 - \beta $.
  - 欲使第二类错误概率足够小: $ n \ge \dfrac{\sigma^2 (u_{\frac{\alpha}{2}} + u_{\frac{1+\beta}{2}})^2}{(\mu_0 - \mu_1)^2} $.

---

注

- 若 $ \mu_0 - \dfrac{\sigma u_\alpha}{\sqrt n} \le \overline{X} \le \mu_0 + \dfrac{\sigma u_\alpha}{\sqrt n} $, 则既接受 $H_0$, 也接受 $H_0'$.
- $\varPhi$ 和 $\varPhi'$ 都是一致最优检验.

- $\varPhi''$ 不是一致最优检验, 并且 $H_0''$ 不存在一致最优检验.

#### 2	方差未知

利用 $ \dfrac{\overline{X} - \mu}{S / \sqrt n} \sim t_{n-1} $, 得到如下 <font color=blue>t 检验</font>:

- $ H_0: \mu \ge \mu_0,\, H_1: \mu \lt \mu_0 $.
  - $ \varPsi:{} $当 $ \overline{X} \ge \mu_0 - \dfrac{S}{\sqrt n} t_{n-1}(\alpha) $ 时接受原假设 $H_0$, 否则否定 $H_0$.
  - 功效函数 $ \beta_\varPsi(\mu, \sigma) = P_{\mu, \sigma} \pqty{\dfrac{\sqrt n}{S} (\overline{X} - \mu_0) < -t_{n-1}(\alpha)} $ 只依赖于 $ \delta = \dfrac{\mu - \mu_0}{\sigma} $.
- $ H_0': \mu \le \mu_0,\, H'_1: \mu > \mu_0 $.
  - $ \varPsi':{} $当 $ \overline{X} \le \mu_0 + \dfrac{S}{\sqrt n} t_{n-1}(\alpha) $ 时接受原假设 $H'_0$, 否则否定 $H'_0$.
- $ H''_0: \mu = \mu_0,\, H''_1: \mu \ne \mu_0 $.
  - $ \varPsi'':{} $当 $ \vqty{\overline{X} - \mu_0} \le \dfrac{S}{\sqrt n} t_{n-1}\pqty{\dfrac{\alpha}{2}} $ 时接受原假设 $H''_0$, 否则否定 $H''_0$.

注: 除非检验水平 $\alpha \ge \dfrac{1}{2}$, 否则 $\varPsi$ 和 $\varPsi'$ 都不是一直最优检验.

### 5.2.2	两个正态总体均值差的检验

设 $\soneto{X}{n_1}$ 和 $\soneto{Y}{n_2}$ 分别是从正态总体 $N(\mu_1, \sigma_1^2)$ 和 $N(\mu_2, \sigma_2^2)$ 中抽取的相互独立的样本.

原假设和对立假设分别为

1. $ H_0: \mu_1 - \mu_2 \ge \mu_0,\, H_1: \mu_1 - \mu_2 < \mu_0 $.
2. $ H'_0: \mu_1 - \mu_2 \le \mu_0,\, H'_1: \mu_1 - \mu_2 > \mu_0 $.
3. $ H''_0: \mu_1 - \mu_2 = \mu_0,\, H''_1: \mu_1 - \mu_2 \ne \mu_0 $.

#### 1	方差已知

利用 $ \overline{X} - \overline{Y} \sim N\pqty{\mu_1 - \mu_2, \dfrac{\sigma_1^2}{n_1} + \dfrac{\sigma_2^2}{n_2}} $, 记 $ \mu_0 = \mu_1 - \mu_2 $, $ U = \dfrac{
	(\overline{X} - \overline{Y}) - \mu_0
}{
	\sqrt{\cfrac{\sigma_1^2}{n_1} + \cfrac{\sigma_2^2}{n_2}}
} $, 则

- $ g:{} $当 $ U \ge -u_\alpha $ 时接受 $H_0$, 否则否定 $H_0$.
- $g':{}$当 $U \le u_\alpha$ 时接受 $H_0'$, 否则否定 $H_0'$.
- $ g'':{} $当 $ \vqty{U} \le u_{\alpha / 2} $ 时接受 $H''_0$, 否则否定 $H''_0$.

#### 2	方差未知

对于 $ \sigma_1^2 = \sigma_2^2 = \sigma^2 $ 的情况, 利用 $ T = \dfrac{
	(\overline{X} - \overline{Y}) - \mu_0
}{
	S_\omega \sqrt{
		\cfrac{1}{n_1} + \cfrac{1}{n_2}
	}
} \sim t_{n_1 + n_2 - 2}, \,
S_\omega^2 = \dfrac{
	\mathrm{SS}_1 + \mathrm{SS}_2
}{n_1 + n_2 - 2} $, 可得到如下<font color=blue>两样本 t 检验</font>:

- $h:{}$当 $ T \ge - t_{n_1 + n_2 - 2}(\alpha) $ 时接受 $H_0$, 否则否定 $H_0$.
- $ h':{} $当 $ T \le t_{n_1 + n_2 - 2}(\alpha) $ 时接受 $H_0'$, 否则否定 $H_0'$.
- $ h'':{} $当 $ \vqty{T} \le t_{n_1 + n_2 - 2}\pqty{\dfrac{\alpha}{2}} $ 时接受 $H''_0$, 否则否定 $H''_0$.

**显著性检验** (希望原假设被否定的检验)

### 5.2.3	正态分布方差的检验

设 $\soneto{X}{n}$ 是从正态总体 $N(\mu, \sigma^2)$ 中抽出的样本.

原假设和对立假设分别为:

1. $ H_0: \sigma^2 \ge \sigma_0^2,\, H_1: \sigma^2 < \sigma_0^2 $.
2. $ H_0': \sigma^2 \le \sigma_0^2,\, H_1 : \sigma^2 > \sigma_0^2 $.
3. $ H_0'': \sigma^2 = \sigma_0^2,\, H_1'': \sigma^2 \ne \sigma_0^2 $.

注: 方差检验的误差较大.

#### 1	均值已知

利用 $ \insum \dfrac{(X_i - \mu)^2}{\sigma^2} \sim \chi_n^2 $,

- $ \phi:{} $当 $ \insum(X_i - \mu)^2 \ge \sigma_0^2 \chi_n^2(1 - \alpha) $ 时接受 $H_0$, 否则否定 $H_0$.
- $ \phi':{} $当 $ \insum (X_i - \mu)^2 \le \sigma_0^2 \chi_n^2(\alpha) $ 时接受 $H_0'$, 否则否定 $H_0'$.
- $ \phi'':{} $当 $ \sigma_0^2 \chi_n^2\pqty{1 - \dfrac{\alpha}{2}} \le \insum(X_i - \mu)^2 \le \sigma_0^2 \chi_n^2\pqty{\dfrac{\alpha}{2}} $ 时接受 $H''_0$, 否则否定 $H''_0$.

#### 2	均值未知

利用 $ \mathrm{SS} \sim \sigma^2 \chi_{n-1}^2 $,

- $ \varphi:{} $当 $ \mathrm{SS} \ge \sigma_0^2 \chi_{n-1}^2(1 - \alpha) $ 时接受 $H_0$, 否则否定 $H_0$.
- $ \varphi':{} $当 $ \mathrm{SS} \le \sigma_0^2 \chi_{n-1}^2(\alpha) $ 时接受 $H_0'$, 否则否定 $H_0'$.
- $ \varphi'':{} $当 $ \sigma_0^2 \chi_{n-1}^2\pqty{1 - \dfrac{\alpha}{2}} \le \mathrm{SS} \le \sigma_0^2 \chi_{n-1}^2\pqty{\dfrac{\alpha}{2}} $ 时接受 $H''_0$, 否则否定 $H''_0$.

### 5.2.π	两个正态分布方差商的检验

设 $\soneto{X}{n_1}$ 和 $\soneto{Y}{n_2}$ 分别是从正态总体 $N(\mu_1, \sigma^2)$ 和 $N(\mu_2, \sigma^2)$ 中抽取的相互独立的样本.

原假设和对立假设分别为

1. $ H_0: \sigma_1^2 / \sigma_2^2 \ge \mu_0,\, H_1: \sigma_1^2 / \sigma_2^2 < \mu_0 $.
2. $ H'_0: \sigma_1^2 / \sigma_2^2 \le \mu_0,\, H'_1: \sigma_1^2 / \sigma_2^2 > \mu_0 $.
3. $ H''_0: \sigma_1^2 / \sigma_2^2 = \mu_0,\, H''_1: \sigma_1^2 / \sigma_2^2 \ne \mu_0 $.

#### 1	均值已知

记 $ U = \dfrac{\dsum_{i=1}^{n_1} (X_i - \mu_1)^2}{\dsum_{i=1}^{n_2} (Y_i - \mu_2)^2} $, 利用 $ \dfrac{n_1 \sigma_1^2}{n_2 \sigma_2^2} \dfrac{1}{U} \sim F_{n_2, n_1} $, 下略.

#### 2	均值未知

利用 $ \dfrac{S_1^2 / S_2^2}{\sigma_1^2 / \sigma_2^2} \sim F_{n_1 - 1,  n_2 - 1} $,

- $ g:{} $当 $ \dfrac{S_1^2}{S_2^2} \ge \dfrac{\sigma_1^2}{\sigma_2^2} F_{n_1 - 1, n_2 - 1}(1 - \alpha) = \dfrac{\sigma_1^2}{\sigma_2^2} F\inv_{n_2 - 1, n_1 - 1}\pqty{\alpha} $ 时接受 $H_0$, 否则否定 $H_0$.
- $ g'':{} $当 $ \dfrac{\sigma_1^2}{\sigma_2^2} F\inv_{n_2-1, n_1-1}\pqty{\dfrac{\alpha}{2}} \le \dfrac{S_1^2}{S_2^2} \le \dfrac{\sigma_1^2}{\sigma_2^2} F_{n_1 - 1, n_2 - 1}\pqty{\dfrac{\alpha}{2}} $ 时接受 $H''_0$, 否则否定 $H''_0$.

### 5.2.4	指数分布参数的检验

#### 1	普通检验

利用 $ 2n\lambda \overline{X} \sim \chi_{2n}^2 $.

#### 2	截尾寿命检验

##### 2.1	定数截尾法

取 $n$ 个元件做试验, 取 $ r \in \N, r < n $, 进行到 $r$ 个元件失效时为止, 所有元件工作的时间为

$ T = Y_1 + \cdots + Y_r + (n-r) Y_r \sim \chi_r^2 $.

##### 2.2	定时截尾法

到时刻 $T_0$ 为止, 所有元件工作的总时间为满足 $ 2\lambda T \dot\sim \chi_{2u+1}^2 $, 其中 $u$ 是已经失效的元件个数.

### 5.2.5	二项分布参数的检验

**普通检验**	

$ H_0: p \le p_0,\, H_1: p > p_0 $.

$ \varphi:{} $当 $X<C$ 时接受 $H_0$, 否则否定 $H_0$.
$$
\beta_\varphi (p) = P_p(X > C)
= 1 - \dsum_{i=0}^C \binom{n}{i} p^i (1-p)^{n-i}.
$$
一般可查表, 对于较大的样本, 难以查表, 可以使用[大样本法](# 5.2.7	大样本检验).

**随机化检验**	

检验 φ 的 **操作特征函数** (**OC 函数**)

**符号检验**	

**非参数检验**	

### 5.2.6	泊松分布参数的检验

利用如下性质:

1. 泊松分布和的函数 (可加性)

   $ X_1 \sim P(\lambda_1),\, X_2 \sim P(\lambda_2) \QRA X_1 + X_2 \sim P(\lambda_1 + \lambda_2) $.

2. $ P_\lambda(X \le k) = \dsum_{i=0}^{k} \dfrac{\e^{-\lambda} \lambda^i}{i!} = \dint_\lambda^{+\infty} \dfrac{\e^{-t}t^k}{k^!} \dt = K_{2k + 2}(2\lambda) $. (卡方分布函数)

3. 若有一批零件寿命服从指数分布, 固定一个时间 $T>0$, 让一个元件从时刻 0 开始工作, 每当这个元件坏了的时候马上用一个新的替换, 则到 $T$ 时替换的次数 $ X \sim P(\lambda T) $, 即 $ P(X = n) = \dfrac{\e^{-\lambda T} (\lambda T)^n}{n!} $. $%用归纳法.$

   - 若有 n 个元件同时开始工作, 每个元件损坏即替换, 则 $ X \sim P(n\lambda T) $.

### 5.2.7	大样本检验

#### 贝伦斯—费歇尔问题

$$
T = \dfrac{
	(\overline{X} - \overline{Y}) - (\mu_1 - \mu_2)
}{\sqrt{
% 	\dfrac{S_1^2}{n_1} + \dfrac{S_2^2}{n_2}
	S_1^2 / n_1 + S_2^2 / n_2
}} \dot\sim \dfrac{
	(\overline{X} - \overline{Y}) - (\mu_1 - \mu_2)
}{\sqrt{
	\sigma_1^2 / n_1 + \sigma_2^2 / n_2
}} \sim N(0, 1).
$$

#### 二项分布参数检验

$$
\dfrac{
	X - np
}{\sqrt{
	np(1-p)
}} \dot\sim N(0, 1).
$$

#### 一般分布参数检验

$$
\dfrac{
	\sum X - n E(X)
}{\sqrt{
	n \Var(X)
}} = \dfrac{
	\sum X - n\mu
}{\sqrt n \sigma}
\sim N(0, 1)
$$

### 5.2.8	贝叶斯方法

#### 基本思路

若原假设的条件概率大于对立假设的条件概率:
$$
P(H_0 \mid \soneto{X}{n}) > P(H_1 \mid \soneto{X}{n})
$$
则接受原假设.

---

#### 正态分布的区间检验

设 $\soneto{X}{n}$ 为抽自正态总体 $N(\theta, \sigma^2)$ 的样本, 其中 $\theta$ 和 $\sigma^2$ 都未知, 考虑检验问题
$$
H_0: a \le \theta \le b,\quad
H_1: \theta < a \or \theta > b\ (a < b).
$$
给 $(\theta, \sigma)$ 以广义先验密度 $\sigma\inv$, 则在得知样本 $\soneto{X}{n}$ 后 $(\theta, \sigma)$ 的后验密度为
$$
\begin{align}
& h(\theta, \sigma) = C_n \sigma^{-(n+1)} \exp\bqty{
	-\dfrac{1}{2\sigma^2}
	\insum (X_i - \theta)^2
},\quad (\theta \in \R,\, \sigma > 0)
\\
& C_n = \pqty{
	\intoi \dd{\sigma} \inti{
		\sigma^{-(n+1)} \exp\bqty{
			-\dfrac{1}{2\sigma^2}
			\insum (X_i - \theta)^2
		}
	} \dd{\sigma}
}\inv
\end{align}
$$
从而得到 $\theta$ 的边缘后验密度为
$$
\begin{align}
h_\theta(\theta) &= C_n \intoi \sigma^{-(n+1)} \exp\bqty{
	-\dfrac{1}{2\sigma^2}
	\insum (X_i - \theta)^2
} \dd{\sigma}
\\
&= D_n \bqty{
	\insum (X_i - \theta)^2
}^{-\tfrac{n}{2}}
= D_n \bqty{
	\mathrm{SS} + n(\overline{X} - \theta)^2
}^{-\tfrac{n}{2}}
\\
&= D_n \mathrm{SS}^{-n} \bqty{
	1 + \dfrac{
		n(\overline{X} - \theta)^2
	}{\mathrm{SS}}
}^{-\tfrac{n}{2}}
= E_n \bqty{
	1 + \dfrac{
		n(\overline{X} - \theta)^2
	}{(n - 1) S^2}
}^{-\tfrac{n}{2}}
\end{align}
$$
令 $ \theta^* = \dfrac{\sqrt n(\theta - \overline{X})}{S} $, 则比较 t 分布密度函数知 $ \theta^* \sim t_{n-1} $, 即
$$
f_{\theta^*} = F_n \pqty{
	1 + \dfrac{\theta^{*2}}{n-1}
}^{-\tfrac{n}{2}}
= \dfrac{
	\pqty{
		1 + \cfrac{\theta^{*2}}{n-1}
	}^{-\tfrac{n}{2}}
}{
	\Beta\pqty{
		\cfrac{n - 1}{2}, \cfrac{1}{2}
	} \sqrt{n - 1}
}
$$
由此可以得到 :star: 
$$
\begin{align}
P(H_0 \mid X_1, \cdots, X_n)
&= P(a \le \theta \le b \mid X_1, \cdots, X_n)
\\
&= P \pqty{ \dfrac{
		\sqrt{n} (a - \overline{X})
	}{S} \le \theta^* \le \dfrac{
		\sqrt{n} (b - \overline{X})
	}{S} \mid X_1, \cdots X_n
} \\
&= T_{n-1} \pqty{
	\dfrac{\sqrt{n} (b - \overline{X})}{S}
} - T_{n-1} \pqty{
	\dfrac{\sqrt{n} (a - \overline{X})}{S}
}
\end{align}
$$

---

**信仰推断法**: 信仰分布, 信仰概率.

## 5.3	拟合优度检验

### 5.3.1	理论分布完全已知且只取有限个值的情况

问题提法

1. $H_0:{}$总体 $X$ 的分布律为 $ F_0(x) $.
2. $H_0:{}$总体 $X$ 的分布律为 $ P(X = x_i) = p_i,\, i = 1, 2, \cdots $.
3. $H_0:{}$总体 $X$ 的概率密度函数为 $f_0(x)$.

对于原假设 $ H_0: P(X = a_i) = p_i\ (i = \oneto{k}) $, 设对 $X$ 进行了足够多的 $n$ 次实验, $ \soneto{X}{n} $ 中等于 $a_i$ 的个数记作 $\nu_i$, 称为 $a_i$ 这个 "类" 的 **经验值** 或 **观察值**, 其近似于**理论值** $np_i$.

**皮尔逊统计量**	$ \chi^2 = \dsum_{i=1}^k \dfrac{
	(np_i - \nu_i)^2
}{np_i}
% = \dsum_{i=1}^k \dfrac{n}{p_i} (f_i - p_i)^2
= \dsum_{i=1}^k \dfrac{\nu_i^2}{n p_i} - n $.

**定理 3.1** :star:	若原假设 $H_0$ 成立, 则 $ \chi^2 \dot\sim \chi_{k-1}^2 $.

**拟合优度**	 $ p(Z_0) = P(Z \ge Z_0 \mid H_0) \approx 1 - K_{k-1}(Z_0) $.

- 统计上的显著性不等于实用上的重要性.

### 5.3.2	理论分布只含有限个值但不完全已知的情况

设总体 $ X \sim P(X = a_i) = p_i(\theta_1, \cdots, \theta_r)\ (i = \oneto{k};\; r \le k - 2) $, 并对 $X$ 进行了足够多的 $n$ 次观察, 记 $\soneto{X}{n}$ 中等于 $a_i$ 的个数为 $\nu_i$, 原假设为 $H_0:{}$总体分布对 $\soneto{\theta^0}{r}$ 成立.

**定理 3.2** :star:	在一定条件下, 若原假设 $H_0$ 成立, 使用<font color=blue>极大似然法</font>估计出 $ (\soneto{\hat\theta}{r}) $, 并由此算出 $ p_i = p_i(\soneto{\hat \theta}{r}) $, 则 $ \chi^2 \dot\sim \chi_{k-1-r}^2 $.

- 此时拟合优度约为 $ p(Z_0) = 1 - K_{k-1-r}(Z_0) $.
- 一般取 $n \ge 50$, 且每一个理论值 $np_i$ 的值都不小于 5.

### 5.3.3	对列联表的应用

$$
\begin{array}{c|cccccc|c}
\hline
B \backslash A & 1 & 2 & \cdots & i & \cdots & a & 和
\\ \hline
1 & n_{11} & n_{12} & \cdots & n_{i1} & \cdots & n_{a1} & n_{\cdot 1}
\\
2 & n_{12} & n_{22} & \cdots & n_{i2} & \cdots & n_{a2} & n_{\cdot 2}
\\
\vdots & \vdots & \vdots && \vdots && \vdots & \vdots
\\
j & n_{1j} & n_{2j} & \cdots & n_{ij} & \cdots & a_{aj} & n_{\cdot j}
\\
\vdots & \vdots & \vdots && \vdots && \vdots & \vdots
\\
b & n_{1b} & n_{2b} & \cdots & n_{ib} & \cdots & n_{ab} & n_{\cdot b}
\\ \hline
和 & n_{1\cdot} & n_{2\cdot} & \cdots & n_{i\cdot} & \cdots & n_{a\cdot} & n
\\ \hline
\end{array}
$$

记 $ P(A = i) = u_i,\, P(B = j) = v_j,\, P(A = i,\, B = j) = p_{ij} $.

$H_0:{}A$ 和 $B$ 独立, 即 $ p_{ij} = u_i v_j $.
$$
\begin{align}
L &= \prod_{i = 1}^a \prod_{j = 1}^b (u_i v_j)^{n_{ij}}
= \prod_{i = 1}^a u_i^{n_{i \cdot}} \prod_{j = 1}^b u_j^{n_{\cdot j}}
\end{align}
$$

$$
\begin{cases}
	0 = \dpdv{\ln L}{u_i} = \dfrac{n_{i\cdot}}{u_i} - \dfrac{n_{a\cdot}}{u_a}
	\\
	0 = \dpdv{\ln L}{v_j} = \dfrac{n_{\cdot j}}{v_j} - \dfrac{n_{a\cdot}}{v_b}
	\\
	\dsum_{i=1}^a n_{i\cdot} = \dsum_{j=1}^b n_{\cdot j} = n
\end{cases}
\QRA \begin{cases}
	\hat u_i = \dfrac{n_{i \cdot}}{n} \\
	\hat v_j = \dfrac{n_{\cdot j}}{n} \\
	\hat p_{ij} = \dfrac{n_{i \cdot} n_{\cdot j}}{n^2}
\end{cases}
$$

自由度为 $ k - 1 - r = ab - 1 - (a + b - 2) = (a-1)(b-1) $.
$$
Z = \dsum_{i=1}^a \dsum_{j=1}^b \dfrac{
	n n_{ij} - n_{i \cdot} n_{\cdot j}
}{n n_{i \cdot} n_{\cdot j}}
\dot\sim \chi_{(a-1)(b-1)}^2
$$
当 $a = b = 2$ 时称为 **四格表**, 此时有
$$
Z = \dfrac{
	n(n_{11} n_{22} - n_{12} n_{21})^2
}{
	n_{1 \cdot} n_{2 \cdot} n_{\cdot 1} n_{\cdot 2}
} \dot\sim \chi_1^2
$$
列联表可用于 **独立性检验** 或 **齐一性检验** 等.

### 5.3.4	总体分布为一般分布的情况

一般分布: 离散型有限个取值, 离散型无限个取值, 连续型.

$H_0:{}$总体分布为 $F(x)$ (或 $ F(x; \soneto{\theta^0}{r}) $).

取划分 $ -\infty = a_0 < a_1 < a_2 < \cdots < a_{k-1} < a_k = +\infty $, 则区间 $I_i = \pbqty{a_{i-1}, a_i}$ 的概率为 $ p_i(\theta_1, \cdots, \theta_r) = F(a_i; \theta_1, \cdots, \theta_r) - F(a_{i-1}; \theta_1, \cdots, \theta_r),\quad (i = \oneto{k}) $.

记 $ H_0':{} $对某一组值 $(\soneto{\theta^0}{r})$, 总体在区间 $I_i$ 内的概率为 $ p_i(\soneto{\theta^0}{r}) $.

记总体 $X$ 的样本值 $x_i$ 落在 $I_i$ 内的个数为 $n_i$, 称为 **实际频数**, 其频率为 $ f_i = \dfrac{n_i}{n} $, **理论频数** 为 $np_i$, 则检验方式同<font color=blueviolet>有限取值</font>的[无参数](# 5.3.1	理论分布完全已知且只取有限个值的情况)或[有参数](# 5.3.2	理论分布只含有限个值但不完全已知的情况)情况相同.

---

- 由于积分等使得表达式的计算较为困难, 实际中可不采取极大似然估计, 而使用矩估计近似替代.

- 如果初始数据就只给出了各区间的数量, 而无精确的数据, 可使用区间的中点近似计算矩估计, 如:
  $$
  \hat\mu = \dfrac{1}{n} \dsum_i m_i \nu_i,\quad
  \hat {\sigma^2} = \dfrac{1}{n} \dsum_{i} \nu_i (m_i - \hat\mu)^2.
  $$

<img src="image\正态总体的假设检验.png">

常用标准正态分布值:
$$
\begin{array}{lll}
	z_{0.1} = 1.281552 & z_{0.05} = 1.644854 & z_{0.025} = 1.959964 \\
	z_{0.01} = 2.326348 & z_{0.005} = 2.575829 & z_{0.0025} = 2.807034 \\
	z_{0.001} = 3.090232
\end{array}
$$
更详细的统计分布表可以参考[概统笔记附录](概统笔记附录.html).



# 第 6 章	回归、相关与方差分析

## 6.1	基本概念

自变量 (预报因子), 因变量 (预报量).

(理论 / 经验) 回归函数 / 回归方程.

非参数回归, 参数回归.

线性回归, 非线性回归.

<span style="border-left: 4px solid #dfe2e5; padding: 0 15px; color: #777777;">回归分析一词的由来的本质原因, 可以参考我之前的一次 [PPT 汇报](D:\LaTeX\project\4_presentation_probability\presentation.pdf).</span>

回归分析的步骤:

1. 建立回归模型.
2. 估计参数, 确定回归方程.
3. 检验与评价回归方程.
4. 利用回归方程进行<u>预测</u>和<u>控制</u>.

## 6.2	一元线性回归

- 一元线性回归模型: $ Y = b_0 + b_1 X + \ve $.
  - 对于每一个 $X_i$, 有 $ Y_i = b_0 + b_1 X_i + \ve_i $.
  - 一般认为 $\ve_i$ 独立同分布 $N(0, \sigma^2)$.
- 对模型进行中心化: $ Y = \beta_0 + \beta_1 (X - \overline{X}) + \ve $.
  - 其中 $ \beta_1 = b_1,\, \beta_0 = b_0 + b_1 \overline{X} $.
  - 预测值记为 $ \hat Y_i = \hat\beta_0 + \hat\beta_1 (X_i - \overline{X}) $.

**注**

- 在回归分析时, 将 $X_i$ 看作非随机<font color=blue>常数</font>. 为了强调这点, 一些资料上使用小写字母表示.
- 中心化是为了方便讨论. 许多资料上将未中心化的系数记为 $\beta_i$, 请注意区分公式中的异同;

### 6.2.1	最小二乘法

#### 1	回归参数的点估计

待定系数的预测值记为 $ \hat{Y}_\i = \alpha_0 + \alpha_1 (X_i - \overline{X}) $, 并用 $ Q(\alpha_0, \alpha_1) = \insum (Y_i - \hat Y)^2 $ 衡量误差, 将最值点记为 $ (\hat\beta_0, \hat\beta_1) $, 则有:
$$
\begin{cases}
	\dpdv{Q}{\alpha_0} = 0, \\
	\dpdv{Q}{\alpha_1} = 0.
\end{cases} \QRA
\begin{cases}
	\hat\beta_0 = \overline{Y}, \\
	\hat\beta_1 = \dfrac{
		\insum (X_i - \overline{X}) Y_i
	}{
		\insum (X_i - \overline{X})^2
	}
\end{cases} \QRA
\begin{cases}
	\hat b_1 = \dfrac{
		\insum (X_i - \overline{X}) Y_i
	}{
		\insum (X_i - \overline{X})^2
	} \\
	\hat b_0 = \overline{Y} - \hat b_1 \overline{X}
\end{cases}
$$
- 其中分子的 $Y_i$ 也可写为 $ (Y_i - \overline{Y}) $, 不影响结果, 此时一般简记为 $ \hat \beta_1 = \dfrac{S_{xy}}{S_{xx}} $.

  注意这里的 $ S_{xy} $ 等, 都<u>未开根号</u>.

- 由上, 我们有 $ \hat Y - \overline{Y} = \hat b_1 (X - \overline{X}) $.

- 除了用 $Q$, 还可以利用 $ Y_i = b_0 + b_1 X_i + \ve_i \sim N(\beta_0 + \beta_1 X_i, \sigma^2) $ 求解最大似然估计, 结果是一样的.

#### 2	参数估计量的性质

1. 无偏估计
   1. $ E(\hat\beta_0) = \beta_0 $.
   2. $ E(\hat\beta_1) = \beta_1 $.
2. 方差
   1. $ \Var(\hat\beta_0) = \dfrac{\sigma^2}{n} $.
   2. $ \Var(\hat\beta_1) = {\sigma^2} \left/ {\insum(X_i - \overline{X})^2} \right. = \dfrac{\sigma^2}{S_{xx}} $.
3. 协方差
   1. $ \hat\beta_0 - E(\hat\beta_0) = \overline{\ve} $.
   2. $ \hat\beta_1 - E(\hat\beta_1) = \dfrac{\insum (X_i - \overline{X}) \ve_i}{\insum (X_i - \overline{X})^2} $.
   3. $ \Cov(\hat\beta_0, \hat\beta_1) = 0 $.
4. 如果 $\ve_i$ 独立同分布 $N(0, \sigma^2)$, 则 $Y_i$ 服从正态分布, 于是 $\hat\beta_0$ 和 $\hat\beta_1$ 服从正态分布, 因此可由不相关推出独立.
   1. $ \hat\beta_0 \sim N\pqty{\beta_0, \dfrac{\sigma^2}{n}} $.
   2. $ \hat\beta_1 \sim N\pqty{\beta_1, \dfrac{\sigma^2}{S_{xx}}} $.
   3. $ \hat b_0 \sim N\pqty{b_0, \pqty{\dfrac{1}{n} + \dfrac{\overline{X}^2}{S_{xx}}} \sigma^2} $.

5. $\hat\beta_0$ 和 $\hat\beta_1$ 是最小方差无偏估计.

#### 3	误差与残差的性质

- 概念

  - 误差 $ \ve_i = Y_i - b_0 - b_1 X_i $.
  - 残差 $ \delta_i = Y_i - \hat b_0 - \hat b_1 X_i = Y_i - \hat Y_i$.
  - 残差平方和 $ Q_\delta = \insum \delta_i^2 $.

  <span style="border-left: 4px solid #dfe2e5; padding: 0 15px; color: #777777;">有些资料中将误差与残差都用 $\ve$ 表示, 有些资料虽然区分了, 但将误差记为 $e$, 或者将残差记为 $e$. 为减少歧义, 这里一律采用上述记号.</span>
  
- 性质

  - 理论值

    - $ E(\delta_i) = 0 $.
    - $ \Var(\delta_i) = \bqty{
      	n - 1 - {
      		(X_i - \overline{X})^2
      	} \left/ {
      		\dsum_{j=1}^{n} (X_j - \overline{X})^2
      	} \right.
      } \sigma^2 $.

  - 观测值

    - $ \insum \delta_i = 0 $.
    - $ \insum X_i \delta_i = 0 $.

    <span style="border-left: 4px solid #dfe2e5; padding: 0 15px; color: #777777;">由最小二乘法中的偏导为零即得; 误差无此性质.</span>

  - 易于计算的形式
    $$
    \begin{align}
    Q_\delta =
    \insum \delta_i^2 &= \insum (Y_i - \overline{Y})^2 - \hat\beta_1 \insum (X_i - \overline{X}) Y_i
    \\
    &= \insum Y_i^2 - n\overline{Y}^2 - \hat\beta_1 \insum (X_i - \overline{X}) Y_i
    \\
    &= {\color{blue} S_{yy} - \hat\beta_1 S_{xy}}
    = S_{yy} - \dfrac{S_{xy}^2}{S_{xx}}
    \end{align}
    $$
    <span style="border-left: 4px solid #dfe2e5; padding: 0 15px; color: #777777;">欲求出回归参数、误差方差的无偏估计，并对回归参数进行区间估计或假设检验，只需求出 $ S_{yy},\, S_{xy} $ 和 $ S_{xx} $ 即可.</span>

- 定理

  - 误差方差的无偏估计: $ \hat\sigma^2 = \dfrac{1}{n-2} \insum \delta_i^2 = \dfrac{Q_\delta}{n-2} $.

  - $ \dfrac{Q_\delta}{\sigma^2} \sim \chi_{n-2}^2 $, 且 $ \overline{Y},\, \hat\beta_1,\, Q_\ve $ 相互独立.


### 6.2.2	区间估计与假设检验

#### 1	平方和表示

$ \mathrm{SS}_总 = \mathrm{SS}_回 + \mathrm{SS}_误 $.

- 总离差平方和 $ \mathrm{SS}_总 = \insum (Y_i - \overline{Y})^2 = \color{blue} S_{yy} $.
- 回归平方和 $ \mathrm{SS}_回 = \insum (\hat Y_i - \overline{Y})^2 = {\color{blue} \hat\beta_1 S_{xy}} = \color{blue} \dfrac{S_{xy}^2}{S_{xx}} $.
- 误差平方和 $ \mathrm{SS}_误 = 2\insum(Y_i - \hat{Y}_i)(\hat{Y}_i - \overline{Y}) + \insum (Y_i - \hat{Y}_i)^2 = \color{blue} Q_\delta $.

#### 2	常用统计量

假定 $\ve_i$ 独立同分布 $N(0, \sigma^2)$, 则下述参数均服从正态分布.

- $ \beta_1 $.
  - $ \dfrac{\hat\beta_1 - \beta_1}{\sigma / \sqrt{S_{xx}}} \sim N(0, 1) $.
  - $ \dfrac{(n-2)\hat\sigma^2}{\sigma^2} \sim \chi_{n-2}^2 $.
  - **t 统计量**: $ \dfrac{\hat\beta_1 - \beta_1}{\hat\sigma / \sqrt{S_{xx}}} \sim t_{n-2} $.
  - **F 统计量**: $ \dfrac{(\hat\beta_1 - \beta_1)^2}{\hat\sigma^2 / S_{xx}} \sim F_{1, n-2} $.
- $ \beta_0 $.
  - $ \dfrac{\hat\beta_0 - \beta_0}{\sigma / \sqrt{n}} \sim N(0, 1) $.
  - **t 统计量**: $ \dfrac{\hat\beta_0 - \beta_0}{\hat\sigma / \sqrt{n}} \sim t_{n-2} $.
  - **F 统计量**: $ \dfrac{(\hat\beta_0 - \beta_0)^2}{\hat\sigma / n} \sim F_{1, n-2} $.
- $ m(x) = \beta_0 + \beta_1 (x - \overline{X}) $.
  - $ \hat m(x) = \hat\beta_0 + \hat\beta_1 (x - \overline{X}) $.
  - $ E[\hat m(x)] = m(x) $.
  - $ \Var[\hat m(x)] = \lambda(x) = \sigma^2 \bqty{\dfrac{1}{n} + \dfrac{(x - \overline{X})^2}{S_{xx}}} $.
  - $ \hat\lambda(x) = \hat\sigma^2 \bqty{\dfrac{1}{n} + \dfrac{(x - \overline{X})^2}{S_{xx}}} $.
  - $ \dfrac{\hat m(x) - m(x)}{\sqrt{\lambda(x)}} \sim N(0, 1) $.
  - $ \dfrac{\hat m(x) - m(x)}{\sqrt{\hat\lambda(x)}} \sim t_{n-2} $.
  - 越靠近样本中心点处预测越精确.
- $ Y_0 = m(x_0) + \ve_0 $.
  - $ \eta = Y_0 - \hat m(x) $.
  - $ E(\eta) = 0 $.
  - $ \Var(\eta) = \sigma^2 \bqty{1 + \dfrac{1}{n} + \dfrac{x - \overline{X}}{S_{xx}}} $.
  - $ \hat\sigma_\eta^2 = \hat\sigma^2 \bqty{1 + \dfrac{1}{n} + \dfrac{x - \overline{X}}{S_{xx}}} $.
  - $ \dfrac{\eta}{\hat\sigma_\eta} \sim t_{n-2} $.

#### 3	显著性检验

区间估计和假设检验直接利用[常用统计量](# 常用统计量)中的结论即可.

比较特殊且实用的是 $ H_0: \beta_1 = 0,\, H_1: \beta_1 \ne 0 $, 这是对线性假设的检验, 又称为 **回归显著性检验**.
代入即得显著性水平 $\alpha$ 下 $ H_0 $ 的拒绝域为:

- **t 统计量**: $ \vqty{T} = \dfrac{\vqty{
  	\hat\beta_1 %- \beta_1
  } \sqrt{S_{xx}}}{\hat\sigma}
  = \dfrac{
  	\sqrt{n - 2} \vqty{S_{xy}}
  }{
  	\sqrt{S_{xx} S_{yy} - S_{xy}^2}
  } \ge t_{n-2}\pqty{\dfrac{\alpha}{2}} $.
- **F 统计量**: $ F = T^2 = \dfrac{(n - 2)\mathrm{SS}_回}{\mathrm{SS}_误} = \dfrac{\mathrm{MS}_回}{\mathrm{MS}_误} \ge F_{1, n-2}(\alpha) $.
- **R 统计量**: $ \vqty{R} = \dfrac{\vqty{S_{xy}}}{\sqrt{S_{xx} S_{yy}}} = \sqrt{\dfrac{\mathrm{SS}_回}{\mathrm{SS}_总}} \ge r_{n-2}(\alpha) $.

---

<p align="center"><b>一元线性回归的方差分析表</b></p>

$$
% \textbf{方差分析表} \\
\begin{array}{ccccc}
\hline
& 自由度\ (\text{df}\,) & 平方和\ (\text{SS}) & 均方\ (\text{MS}) & F
\\ \hline
回归分析 & 1 & \mathrm{SS_回} & \mathrm{MS_回} &
\\
残差 & n-2 & \mathrm{SS_误} & \mathrm{MS_误} & \dfrac{\mathrm{MS}_回}{\mathrm{MS}_误}
\\
总计 & n-1 & \mathrm{SS}_总 &&
\\ \hline
\\ \hline
相关系数绝对值 & \vqty{R} &&&
\\
相关系数的平方 & R^2 &&&
\\ \hline
\end{array}
$$

### 6.2.3	预测与控制

#### 1	点预测

点预测值 $ \hat Y_0 = \hat b_0 + \hat b_1 x_0 $ 与随机变量 $ Y_0 = b_0 + b_1 x_0 + \ve_0 $ 有相同的数学期望.

#### 2	区间预测

$ \hat Y_0 $ 和 $ \delta_0 $  都可以用 $Y_i$ 线性表示, 因此均为正态分布, 并有
$$
\begin{align}
\hat Y_0 &= \overline{Y} + \hat \beta_1 (X_0 - \overline{X})
\\
&= \insum \pqty{
	\dfrac{1}{n} + \dfrac{
		(X_i - \overline{X}) (X_0 - \overline{X})
	}{S_{xx}}
} Y_i
\\
&\sim N\pqty{
	b_0 + b_1 x_0, \pqty{
		\dfrac{1}{n} + \dfrac{
			(X_0 - \overline{X})^2
		}{S_{xx}}
	} \sigma^2
} \\
\delta_0 &= Y_0 - \hat Y_0
\\
&\sim N\pqty{
	0, \pqty{
		1 + \dfrac{1}{n} +
		\dfrac{(X_0 - \overline{X})^2}{S_{xx}}
	} \sigma^2
}
\end{align}
$$
结合 $ \dfrac{(n-2) \hat\sigma^2}{\sigma^2} \sim \chi_{n-2}^2 $, 因此有
$$
\dfrac{
	\hat Y_0 - Y_0
}{
	\hat \sigma \sqrt{
		1 + \cfrac{1}{n} + \cfrac{
			(X_0 - \overline{X})^2
		}{S_{xx}}
	}
} \sim t_{n-2}
$$

#### 3	控制

**注意**: 回归方程 $ \hat Y = \hat b_0 + \hat b_1 X $ <font color=red>不可</font>推出 $ \hat X = \dfrac{Y - \hat b_0}{\hat b_1} $, 但是可以估计 $ X_0 = \dfrac{\hat Y - \hat b_0}{\hat b_1} $, 即回归分析的控制作用.

## 6.3	多元线性回归

- **多元线性回归模型**: $ Y = b_0 + b_1 X_1 + b_2 X_2 + \cdots + b_p X_p + \ve $.

  - 观测值: $ Y_i = b_0 + b_1 X_{1i} + b_2 X_{2i} + \cdots + b_p X_{pi} + \ve $.
  - 一般认为 $ \ve_i $ 独立同分布 $ N(0, \sigma^2) $, 并且 $X_i$ **非随机**.

- 对模型进行**中心化**: $ Y = \beta_0 + \beta_1 X_1^* + \beta_2 X_2^* + \cdots + \beta_p X_p^* + \ve $.
  - 其中 $ X_k^* = X_k - \overline{X}_k,\, \beta_k = b_k,\, k = 1, \cdots, p,\, \beta_0 = b_0 + b_1 \overline{X}_1 + \cdots + b_p \overline{X}_p $.
  - 方便起见, 之后我会将未中心化时的 $X_i$ 记为 $x_i$, 中心化后的 $X_k^*$ 记为 $X_k$.

- 表示为矩阵的形式: $ \bm y = \bm X \bm \beta + \bm \ve $, 其中 $\bm X$ 称为**设计矩阵**, 并且这里已中心化.
  $$
  \bm y = \pvc{Y},\quad
  \bm \beta = \begin{pmatrix}
  	\beta_0 \\ \beta_1 \\ \vdots \\ \beta_p
  \end{pmatrix},\quad
  \bm X = \begin{pmatrix}
      1 & X_{11} & X_{12} & \cdots & X_{1p} \\
      1 & X_{21} & X_{22} & \cdots & X_{2p} \\
      \vdots & \vdots & \vdots && \vdots \\
      1 & X_{n1} & X_{n2} & \cdots & X_{np}
  \end{pmatrix},\quad
  \bm \ve = \pvc{\ve}.
  $$

**注**: 设计矩阵的元素一般未中心化, 并且无上式中的第一列. 这样做是为了讨论方便.

### 6.3.1	最小二乘法

#### 1	回归参数的点估计

记预测值为 $ \bm{\hat{y}} = \bm X \bm \alpha $, 用下式衡量误差
$$
Q(\alpha_0, \alpha_1, \cdots, \alpha_p) = \insum \pqty{
	Y_i - \alpha_0 - X_{1i} \alpha_1 - \cdots - X_{pi} \alpha_p
}^2
$$
并将极值点记为 $ \hat\beta_0, \hat\beta_1, \cdots, \hat\beta_p $, 令偏导为零则有
$$
\begin{cases}
    \dpdv{Q}{\alpha_0} = 0, \\
    \dpdv{Q}{\alpha_1} = 0, \\
    \quad \cdots \cdots \\
    \dpdv{Q}{\alpha_p} = 0.
\end{cases}
\QRA \begin{cases}
    n \hat \beta_0 = \insum {y_i}, \\
    l_{11} \hat \beta_1 + l_{12} \hat \beta_2 + \cdots + l_{1p} \hat \beta_p = \insum X_{1i} y_i = S_{x_1y}, \\
    \quad \cdots \cdots \\
    l_{p1} \hat \beta_1 + l_{p2} \hat \beta_2 + \cdots + l_{pp} \hat \beta_p = \insum X_{pi} y_i = S_{x_p y}.
\end{cases}
$$
其中 $ l_{uv} = \insum X_{ui} X_{vi} = S_{XuXv},\, \bm L = \bm X\trans \bm X $.

于是方程组化为*正则方程* : $ \bm L \bm{\hat\beta} = \bm X\trans \bm y_{(n)} $.

记 $ \bm C = \bm L\inv $, 则有 $ \bm{\hat \beta} = (\bm X\trans \bm X)\inv \bm X\trans \bm y = \bm C \bm X\trans \bm y $.

类似的, 这也是最大似然估计量.

#### 2	参数估计量的性质

- $ \bm{\hat \beta}$ 是 $\bm \beta$ 的无偏估计.
- $ \Cov(\bm{\hat\beta}, \bm{\hat\beta}) = (\bm X\trans \bm X)\inv \sigma^2 = \bm C \sigma^2 $.
  - 方差
    - $ \Var(\hat \beta_0) = \dfrac{\sigma^2}{n} $.
    - $ \Var(\hat\beta_i) = c_{ij} \sigma^2 $.
  - 协方差
    - $ \Cov(\hat \beta_0, \hat \beta_i) = 0\ (i = \oneto{p}) $.
    - $ \Cov(\hat\beta_i, \hat\beta_j) = c_{ij} \sigma^2 $.

#### 3	误差与残差的性质

概念同[一元线性回归](# 3	误差与残差的性质).

- 性质

  - 残差的性质

    - $ \insum \delta_i = 0 $.
    - $ \insum X_{ki} \delta_i = 0 $.

    <span style="border-left: 4px solid #dfe2e5; padding: 0 15px; color: #777777;">由最小二乘法中的偏导为零即得.</span>

  - 残差平方和的易于计算的形式
    $$
    Q_\delta = S_{yy} - (\hat\beta_1 S_{x_1y} + \hat\beta_2 S_{x_2y} + \cdots + \hat\beta_p S_{x_p y}).
    $$

- 定理

  - $ \hat\sigma^2 = \dfrac{Q_\delta}{n - p - 1} $ 是 $ \sigma^2 $ 的无偏估计.
  - $ \dfrac{Q_\delta}{\sigma^2} \sim \chi_{n-p-1}^2 $.
  - 注意: 这里参数的数量为 $ p + 1 $.

### 6.3.2	区间估计与假设检验

显著性检验的假设为 $ H_0: \beta_1 = \beta_2 = \cdots = \beta_p = 0 $.

- 统计量
  - $ \dfrac{\mathrm{SS}_回}{\sigma^2} \sim \chi_p^2 $.
  - $ \dfrac{\mathrm{SS}_误}{\sigma^2} \sim \chi_{n-p-1}^2 $.
- 拒绝域
  - F 统计量: $ F = \dfrac{\mathrm{SS}_回 / p}{\mathrm{SS}_误 / (n - p - 1)} = \dfrac{\mathrm{MS}_回}{\mathrm{MS}_误} \ge F_{p, n-p-1}(\alpha) $.
  - R 统计量: $ \vqty{R} = \sqrt{\dfrac{\mathrm{SS}_回}{\mathrm{SS}_总}} \ge r_{n - p - 1}(\alpha) $.

---

<p align="center"><b>多元线性回归的方差分析表</b></p>

$$
% \textbf{方差分析表} \\
\begin{array}{ccccc}
\hline
& 自由度\ (\text{df}\,) & 平方和\ (\text{SS}) & 均方\ (\text{MS}) & F
\\ \hline
回归分析 & p & \mathrm{SS_回} & \mathrm{MS_回} &
\\
残差 & n-p-1 & \mathrm{SS_误} & \mathrm{MS_误} & \dfrac{\mathrm{MS}_回}{\mathrm{MS}_误}
\\
总计 & n-1 & \mathrm{SS}_总 &&
\\ \hline
\\ \hline
相关系数绝对值 & \vqty{R} &&&
\\
相关系数的平方 & R^2 &&&
\\ \hline
\end{array}
$$

### 6.3.3	预测与控制

1. 点预测

   $ E(\hat Y) = E(Y) $, 故可用 $ \hat Y = \hat\beta_0 + \hat\beta_1 X_1 + \cdots + \hat\beta_p X_p $ 进行点预测.

2. 区间预测

$$
T = \dfrac{
	\hat Y_0 - Y_0
}{\hat\sigma \sqrt{
	1 + (1, \bm x_0\trans) (\bm X\trans \bm X)\inv
	\begin{pmatrix}
		1 \\ x_0
	\end{pmatrix}
}} \sim t_{n - p - 1}.
$$

## 6.4	相关分析

6.4.1	相关系数的估计和检验

6.4.2	偏相关

6.4.3	复相关

## 6.5	方差分析

试验指标.

可控因素, 不可控因素.

单因素方差分析, 多因素方差分析.

### 6.5.1	单因素方差分析

#### 1	数学模型

因素 $A$ 有 $s$ 个 **水平** $ \soneto{A}{s} $.
$$
\begin{array}{c|c|c}
\hline
水平 & 观察值 & 样本均值
\\ \hline
\begin{matrix}
	A_1 \\ A_2 \\ \vdots \\ A_s
\end{matrix}
& \begin{matrix}
	x_{11} & x_{12} & \cdots & x_{1n_1} \\
	x_{21} & x_{22} & \cdots & x_{2n_2} \\
	\vdots & \vdots && \vdots \\
	x_{s1} & x_{s2} & \cdots & x_{sn_s}
\end{matrix}
& \begin{matrix}
	\mu_1 \\ \mu_2 \\ \vdots \\ \mu_s
\end{matrix}
\\ \hline
\end{array}
$$

- 记 $ X_{ij} = \mu_i + \ve_{ij} $, 假定 $ \ve_{ij} \sim N(0, \sigma^2) $ 且相互独立.
  - 总次数 $ n = \dsum_{i=1}^s n_i $.
  - 总平均 $ \mu = \dfrac{1}{n} \dsum_{i=1}^s n_i \mu_i $.
- 水平 $A_i$ 的效应 $ \delta_i = \mu_i - \mu $.
  - $ X_{ij} = \mu + \delta_i + \ve_{ij} $.
  - $ \dsum_{i=1}^s n_i \delta_i = 0 $.
- 假设
  - $ H_0 : \mu_1 = \mu_2 = \cdots = \mu_s $.
  - $ H_0 : \delta_1 = \delta_2 = \cdots = \delta_s $.

#### 2	总离差平方和

##### 2.1	分解

- **总离差平方和** $ \mathrm{SS}_\text{T} = \dsum_{i=1}^s \dsum_{j=1}^{n_i} (X_{ij} - \overline{X})^2 $.

  - 组内均值 $ \overline{X}_{i\cdot} = \dfrac{1}{n_i} \dsum_{j=1}^{n_i} X_{ij} $.
  - 总平均值 $ \overline{X} = \dfrac{1}{n} \dsum_{i=1}^s \dsum_{j=1}^{n_i} X_{ij} = \dfrac{1}{n} \dsum_{i=1}^s n_i \overline{X}_{i\cdot} $.

- 总离差平方和的 **分解** $ \mathrm{SS_T} = \mathrm{SS_E} + \mathrm{SS_A} $.

  - **误差平方和** (组内方差) $ \mathrm{SS_E} = \dsum_{i=1}^s \dsum_{j=1}^{n_i} (X_{ij} - \overline{X}_{i\cdot})^2 $.

  - **效应平方和** (组间方差) $ \mathrm{SS_A} = \dsum_{i=1}^s \dsum_{j=1}^{n_i} (\overline{X}_{i\cdot} - \overline{X})^2 $.
    $$
    \mathrm{SS_A} = \dsum_{i=1}^s n_i \overline{X}_{i\cdot}^2 - n\overline{X}^2
    = \dsum_{i=1}^s \dfrac{(\sum X_{i})^2}{n_i} - \dfrac{(\sum X)^2}{n}.
    $$

##### 2.2	统计特征

- $ \mathrm{SS_E} $.
  - $ \dfrac{
    	\dsum_{j=1}^{n_i}(X_ij - \overline{X}_{i\cdot})^2
    }{\sigma^2} \sim \chi_{n_i - 1}^2 $.
  - $ \dfrac{\mathrm{SS_E}}{\sigma^2} \sim \chi_{n-s}^2 $.
  - $ E(\mathrm{SS_E}) = (n - s) \sigma^2 $.
  - $ \Var(\mathrm{SS_E}) = 2(n - s) \sigma^2 $.
- $ \mathrm{SS_A} $.
  - $ E(\mathrm{SS_A}) = (s - 1) \sigma^2 + \dsum_{i=1}^s n_i \delta_i^2 $.
  - 当 $H_0$ 成立时, 有
    - $ E(\mathrm{SS_A}) = (s - 1) \sigma^2 $.
    - $ \dfrac{\mathrm{SS_A}}{\sigma^2} \sim \chi_{s-1}^2 $.
    - $ \mathrm{SS_A} $ 与 $ \mathrm{SS_E} $ 相互独立.

#### 3	拒绝域

拒绝 $H_0$, 即认为因素 $A$ 各个水平的试验指标之间有显著差异.
$$
F = \dfrac{
	\mathrm{SS_A} / (s - 1)
}{
	\mathrm{SS_E} / (n - s)
} = \dfrac{
	\mathrm{MS_A}
}{\mathrm{MS_E}}
\ge F_{s - 1, n - s} (\alpha).
$$

---

<p align="center"><b>SUMMARY 表</b></p>

$$
\begin{array}{ccccc}
\hline
水平 &观测数 & 总和 & 组均值 & \small \mathrm{SS}_i
\\ \hline
水平\ \small 1 & \small n_1 & \small \dsum_{j=1}^{n_1} x_{1j} & \small \overline{x}_{1\cdot} & \small \mathrm{SS}_1
\\
水平\ \small 2 & \small n_1 & \small \dsum_{j=1}^{n_2} x_{2j} & \small \overline{x}_{2\cdot} & \small \mathrm{SS}_2
\\
\vdots & \vdots & \vdots & \vdots & \vdots
\\
水平\ \small s & \small n_s & \small \dsum_{j=s}^{n_s} x_{sj} & \small \overline{x}_{s\cdot} & \small \mathrm{SS}_s
\\ \hline
\end{array}
$$

---

<p align="center"><b>单因素方差分析表</b></p>

$$
\begin{array}{cccccc}
\hline
差异源 & 平方和\ (\mathrm{SS}) & 自由度\ (\mathrm{df}) & 均方\ \mathrm{MS} & F & F\ 分位数\ (F\text{ crit})
\\ \hline
组间 & \mathrm{SS_A} & s - 1 & \mathrm{MS_A} && F_{s - 1, n - s}(\alpha)
\\
组内 & \mathrm{SS_E} & n - s & \mathrm{MS_E} & \dfrac{\mathrm{MS_A}}{\mathrm{MS_E}} &
\\ \hline
总和 & \mathrm{SS_T} & n - 1 &&&
\\ \hline
\end{array}
$$

上述参数的计算见[总离差平方和](# 2	总离差平方和).

#### 4	参数估计

- $ \hat\mu_i = \overline{X}_{i\cdot} $.
- $ \hat\mu = \overline{X} $.
- $ \hat\delta_i = \hat\mu_i - \hat\mu $.
- $ \hat\sigma^2 = \mathrm{MS_E} $.

