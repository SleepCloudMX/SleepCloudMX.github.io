<h1 align="center">概率论与数理统计</h1>

$$
\text{眠云跂石整理}

% 字符
\renewcommand{\i}{\textup{i}}
\newcommand{\e}{\textup{e}}
\newcommand{\ve}{\varepsilon}
\newcommand{\Beta}{\mathit{B}}

% 上下标
\newcommand{\trans}{^\mathrm{T}}
\newcommand{\inv}{^{-1}}
\newcommand{\adj}[1]{^{\pqty{#1^*}}}

% 特定内容
\newcommand{\oneton}{1,2,\cdots,n}
\newcommand{\oneto}[1]{1,2,\cdots,#1}

\newcommand{\ssto}[3]{#1_1 #3 #1_2 #3 \cdots #3 #1_{#2}}
\newcommand{\ssup}[3]{#1^1 #3 #1^2 #3 \cdots #3 #1^{#2}}
\newcommand{\soneto}[2]{\ssto{#1}{#2}{,}}
\newcommand{\splus}[2]{\ssto{#1}{#2}{+}}

\newcommand{\aqty}[1]{\expval{#1}}
\newcommand{\pbqty}[1]{\left(#1\right]}
\newcommand{\bpqty}[1]{\left[#1\right)}
\newcommand{\floor}[1]{\left\lfloor#1\right\rfloor}
\newcommand{\ceil}[1]{\left\lceil#1\right\rceil}

\newcommand{\ccdots}{\cdot\cdots\cdot}

% 下面几个只是为了方便一点点而已
\newcommand{\dx}{\dd{x}}
\newcommand{\dy}{\dd{y}}
\newcommand{\dz}{\dd{z}}
\newcommand{\dt}{\dd{t}}
\newcommand{\ds}{\dd{s}}

% 如果只使用 \dd{x}\dd{y} 的话, 中间会有多余的间隔.
\newcommand{\ddd}[2]{\,\mathrm{d}#1\mathrm{d}#2}
\newcommand{\dxdy}{\,\mathrm{d}x\mathrm{d}y}
\newcommand{\dydz}{\,\mathrm{d}y\mathrm{d}z}
\newcommand{\dzdx}{\,\mathrm{d}z\mathrm{d}x}
\newcommand{\dudv}{\,\mathrm{d}u\mathrm{d}v}
\newcommand{\dxdydz}{\,\mathrm{d}x\mathrm{d}y\mathrm{d}z}

% 函数名
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\Corr}{Corr}

% 运算符
\newcommand{\dint}{\displaystyle\int}
\newcommand{\inti}{\dint_{-\infty}^{+\infty}}
\newcommand{\intoi}{\dint_0^{+\infty}}

\newcommand{\intl}{\displaystyle\int\limits}
\newcommand{\iintl}{\displaystyle\iint\limits}
\newcommand{\iiintl}{\displaystyle\iiint\limits}

\newcommand{\dsum}{\displaystyle\sum}
\newcommand{\nsum}{\dsum_{n=1}^\infty}
\newcommand{\nosum}{\dsum_{n=0}^\infty}
\newcommand{\insum}{\dsum_{i=1}^n}

\newcommand{\dprod}{\displaystyle\prod}
\newcommand{\nprod}{\dprod_{n=1}^\infty}

\newcommand{\xlim}{\lim\limits_{x\to x_0}}
\newcommand{\nlim}{\lim\limits_{n\to\infty}}
\newcommand{\clim}[1]{\lim\limits_{#1\to\infty}}
\newcommand{\ulim}{\overline\lim\limits_{n\to\infty}}
\newcommand{\dlim}{\underline\lim\limits_{n\to\infty}}
% 注意这里的 d 是 down, 而不是 displaystyle

% 缩写
\newcommand{\bm}[1]{\boldsymbol{#1}}
\newcommand{\LRA}{\Leftrightarrow}
\newcommand{\RLA}{\Leftrightarrow}
\newcommand{\LA}{\Leftarrow}
\newcommand{\RA}{\Rightarrow}

\newcommand{\lra}{\leftrightarrow}
\newcommand{\rla}{\leftrightarrow}
\newcommand{\la}{\leftarrow}
\newcommand{\ra}{\rightarrow}

\newcommand{\QRLA}{\quad\RLA\quad}
\newcommand{\QRA}{\quad\RA\quad}
\newcommand{\LLRA}{\Longleftrightarrow}

\newcommand{\QNRA}{\quad\nRightarrow\quad}
\newcommand{\qnra}{\quad\nrightarrow\quad}

% displaytsyle 的指令缩写
\newcommand{\ddv}{\displaystyle\dv}
\newcommand{\dpdv}{\displaystyle\pdv}
$$

# 第 1 章	事件的概率

## 组合公式

由 $ \displaystyle (a+b)^n = \sum_{i=0}^n \binom{n}{i} a^ib^{-ni} $ 知
$$
\binom{n}{0} + \binom{n}{1} + \cdots + \binom{n}{n} = 2^n
\\
\binom{n}{0} - \binom{n}{1} - \cdots + (-1)^{-1} \binom{n}{n} = 0
$$
---

由 $ (1+x)^{m+n} = (1+x)^m (1+x)^n $ 知
$$
\binom{m+n}{k} = \sum_{i=0}^k \binom{m}{i} \binom{n}{k-i}
$$
特别地, 当 $m=k=n$ 时,
$$
\binom{2n}{n} = \sum_{i=0}^n \binom{n}{i}^2
$$
第一式还可以写作下式, 并可以从直观上理解.
$$
\sum_{k_1+k_2=k} \binom{n_1}{k_1} \binom{n_2}{k_2} = \binom{n_1+n_2}{k_1+k_2}
$$
此外还有下式, 也可以从直观上理解.
$$
\sum_{n_1+n_2 = n} \binom{n_1}{k_1} \binom{n_2}{k_2} = \binom{n_1+n_2+1}{k_1+k_2+1}
$$

---

多项式系数：$ \dfrac{n!}{r_1!\cdots r_k!} $.

---

利用第一式 (杨辉恒等式) 数归得第二式 (或直观理解)
$$
\binom{n+m}{m} + \binom{n+m}{m+1} = \binom{n+m+1}{m+1}
\\
\sum_{r=0}^m \binom{n-1+r}{r} = \binom{n+m}{m}
$$

---

由负指数二项展开式 $ (1-x)^{-r} = \displaystyle \sum_{i=0}^\infty \binom{-r}{i} (-x)^{i} = \sum_{i=0}^\infty \binom{i+r-1}{r-1} x^i $ 知
$$
\sum_{i=0}^\infty \binom{i+r-1}{r-1} = 0
\\
\sum_{i=0}^\infty \binom{i+r-1}{r-1} (-1)^i = 2^{-r}
\\
p^{-r} = \sum_{i=0}^\infty \binom{i+r-1}{r-1} p^r (1-p)^i
$$
原式两边求导, 并令 $x=1-p$, 得
$$
rp^{-r-1} = \sum_{i=0}^\infty i \binom{i+r-1}{r-1}(1-p)^{i-1}
$$

---

[Stirling 数, 拆分数, 装箱问题, Burnside 定理与 Polya 定理](https://www.cnblogs.com/mooleetzi/p/11330256.html#:~:text=%E7%BB%84%E5%90%88%E6%95%B0%E5%85%AC%E5%BC%8F%201%20C%28k%20n%29%20%3D%20C%28n%20%E2%88%92%201%2C,i%20%E2%88%92%20...%208%20C%28n%2C%20m%29%20%E7%9A%84%E5%A5%87%E5%81%B6%E6%80%A7%3An%26m%3Dm%E4%B8%BA%E5%A5%87%EF%BC%8C%E5%90%A6%E5%88%99%E4%B8%BA%E5%81%B6%EF%BC%88luca%20)

## 事件的运算

- 记号

  - $ A+B \equiv A \cup B $.
  - $ AB \equiv A \cap B $.
  - $ A-B \equiv A\overline{B} $.

- 加法

  - 交换律：$ A+B=B+A $.

  - 结合律：$ (A+B)+C =A+(B+C) $.

    <span style="background-color:#eeeee; color:#777777">于是可定义 $ A+B+C = (A+B)+C $. </span>

  - 自加：$ A+A = A $.

- 乘法

  - 交换律：$ AB=BA $.

  - 结合律：$ (AB)C = A(BC) $.

    <span style="background-color:#eeeee; color:#777777">于是可定义 $ ABC = (AB)C $. </span>

  - 自乘：$ AA = A $.

- 分配律

  - 加法与乘法：$ (A+B)C = AC+BC $.

  - 减法与乘法：$ (A-B)C = AC-BC $.

    <span style="background-color:#eeeee; color:#777777">本质为 $ ABC = (AC)(BC) $, 这个式子在推导中是有用的.</span>

- 减法

  - $ A-B = A\overline{B} \ne A + (-B) $.
  - $ A \subseteq B \RLA A-B = \varnothing $.
  - $ A=B \RLA A-B = B-A = \varnothing $.

- 无消去律

  - $ A+B = A+C \nRightarrow B=C $.
  
  - $ A-B = A-C \nRightarrow B=C $.

- 混合运算

  - $ (A+B)-C \ne A+(B-C) $. (因为减法本质上是乘法)

    <span style="background-color:#eeeee; color:#777777">因此 $ A+B-C $ 没有意义, 除非定义运算顺序或优先级.</span>

  - $ A - (B+C) = A-B-C = (A-C) - (B-C) $.

  - $ A-(B-C) = (A-B)C = AC - BC $.

- 负号 (补集)

  - $ -(A+B) = (-A)(-B) $.

  - $ -(A-B) = B-A = (-A)B $.

  - $ -(AB) = (-A) + (-B) $.

    <span style="background-color:#eeeee; color:#777777">理论上可以这么写, 实际上用 $\overline{A}$ 的符号会更方便.</span>

- 互斥

  - $A$ 与 $B$ 互斥 $\QRLA AB = \varnothing \QRLA P(AB) = 0 $. 

  - $ AC=BC \QRLA A-B $ 与 $ B-A $ 均与 $C$ 互斥 $ \QRLA P(\overline{A}BC) = P(A\overline{B}C) =0 $.

    <span style="background-color:#eeeee; color:#777777">当且仅当 $ C = \Omega$ 时, 可由此推出 $A=B$.</span>

  - $A$ 与 $B$ 互斥 $ \QRA AC $ 与 $BC$ 互斥 $ \QRA P(C(A+B)) = P(AC) + P(BC) $.

- 对立

  - $A$ 与 $B$ 对立 $ \QRLA AB = \varnothing $ 且 $ A+B=\Omega $.
  - $ \overline{A_1A_2\cdots A_n} = \overline{A}_1 + \overline{A}_2 + \cdots + \overline{A}_n $.
  - $ \overline{A_1 + A_2 + \cdots + A_n} = \overline{A}_1 \overline{A}_2 \cdots \overline{A}_n $.

- 条件概率

  - 定义：$ P(A \mid B) = P(AB) / P(B) $.
  - 全概率公式：若两两互斥的 $ B_i $ 之交为必然事件, 则 $ P(A) = P(B_1)P(A \mid B_1) + P(B_2)P(A \mid B_2) + \cdots $.
  - 贝叶斯公式:
    - $ P(B \mid A) = \dfrac{P(B)P(A \mid B)}{P(A)} $.
    - $ P(B_i \mid A) = \dfrac{P(AB_i)}{P(A)} = \dfrac{ P(B_i) P(A \mid B_i) }{ \displaystyle \sum P(B_j) P(A \mid B_j) } $.

- 几率

  - 定义：$ O(A) = \dfrac{P(A)}{1-P(A)} = \dfrac{P(A)}{P(\overline{A})} $.
  - 贝叶斯公式：$ O(B \mid A) = \dfrac{P(B \mid A)}{P(\overline{B} \mid A)} = \dfrac{P(B)P(A \mid B)}{P(A)P(\overline{B} \mid A)} = \dfrac{P(B)P(A \mid B)}{P(\overline{B})P(A \mid \overline{B})} = O(B) \dfrac{P(A \mid B)}{P(A \mid \overline{B})} $.
  - 贝叶斯因子：$ \text{BF} = \dfrac{P(A \mid B)}{P(A \mid \overline{B})} $, 故 $ O(B \mid A) = \mathrm{BF} \cdot O(B) $.

- 促进作用的性质

  - 具有对称性：$A$ 促进 $B$, 则 $B$ 促进 $A$, 即

    $ P(A \mid B) > P(A) \QRLA P(B \mid A) > P(B) $.

  - 不具有传递性：$B$ 促进 $A$ 且 $C$ 促进 $B$ 不能推出 $C$ 促进 $A$, 即

    $ P(A \mid B) > P(A),\, P(B \mid C) > P(B) \quad\nRightarrow\quad P(A \mid C) > P(A) $.

  - 若 $B$ 和 $C$ 都促进 $A$, 则 $B+C$ 一定促进 $A$, 但 $BC$ 和 $B-C$ 不一定促进 $A$, 即

    $ P(A \mid B) > P(A),\, P(A \mid C) > P(A) \QRLA P(A \mid B+C) > P(A) $.

  - 若 $B$ 促进 $A$, 则 $\overline{B}$ 抑制 $A$, $B$ 抑制 $\overline{A}$, $\overline{B}$ 促进 $\overline{A}$, 即

    $ P(A \mid B) > P(A) \QRLA P(A \mid \overline{B}) < P(A) \QRLA P(\overline{A} \mid B) < P(\overline{A}) \QRLA P(\overline{A} \mid \overline{B}) > P(\overline{A}) $.
    
    $ P(A \mid B) = P(A) \QRLA P(A \mid \overline{B}) = P(A) \QRLA P(\overline{A} \mid B) = P(\overline{A}) \QRLA P(\overline{A} \mid \overline{B}) = P(\overline{A}) $.

- 独立

  - $A$ 与 $B$ 独立 $ \QRLA P(AB) = P(A)P(B) \QRA P(A \mid B) = P(A) $.
  - 两两独立: $ \forall i, j(1 \le i, j \le n, i \ne j): P(A_i A_j) = P(A_i) P(A_j) $.
  - 相互独立: $ \forall 1 < k \le n,\, 1 \le i_1 \lt i_2 \lt \cdots \lt i_k \le n: P(A_{i_1} A_{i_2} \cdots A_{i_k}) = P(A_{i_1}) P(A_{i_2}) \cdots P(A_{i_k}) $.
  - 相互独立 $ \RA $ 两两独立, 反之不一定成立.
  - 独立事件的任一部分也独立.
  - 若 $ \soneto{A}{n} $ 独立, $B_i = A_i$ 或 $ \overline{A}_i $, 则 $ \soneto{B}{n} $ 也独立.

- 独立事件的概率

  - 乘法：$ P(\prod{E_i}) = \prod P(E_i) $.
  - 加法：$ P(\sum{E_i}) = 1 - P(\prod{\overline{E_{i}}}) = 1 - \prod P({\overline{E_i}}) $.
  - 实例:

    $ \begin{align} \text{} P(E_0 + E_1E_2) &= 1 - P(\overline{E}_0 \overline{E_1E_2}) = 1 - (1-P(E_0))(1-P(E_0E_1)) \\&= P(E_0) + P(E_1)P(E_2) - P(E_0)P(E_1)P(E_2). \end{align} $

- 运算定理

  - 加法定理 (并集)：$ P(A+B) = P(A) + P(B) \QRLA AB = \varnothing \QRLA P(AB) = 0 $.
  - 减法定理 (差集)：$ P(A-B) = P(A) - P(B) \QRLA A \supseteq B \QRLA P(B-A) = 0 $.
  - 乘法定理 (交集)：$ P(AB) = P(A)P(B) \QRLA A $ 与 $B$ 独立.
  - 加法推论 (补集)：$ P(A^c) = P(\overline{A}) = 1 - P(A) $ 恒成立.

- 表为互斥事件

  - $  \displaystyle \sum A_i = A_1 + \overline{A}_1A_2 + \cdots + \overline{A}_1\overline{A}_2 \cdots \overline{A}_{n-1} A_n  $.

    - $ A+B = A + (B-A) $.
    - $ A+B+C = A + (B-A) + (C-B-A) $.

  - 设 $ \displaystyle f(m) = \sum_{k,l} \pqty{ \prod_{i=1}^m{A_{k_i}} \prod_{j=1}^{n-m}{\overline{A}_{l_j}}} $, 则 $ \displaystyle \sum_{i=1}^n A_i = \sum_{m=1}^n f(m) $.

    - $ A+B = (B-A) + (A-B) + AB $.
    - $ A+B+C = ABC + (BC-A) + (AC-B) + (AB-C) + (A-B-C) + (B-A-C) + (C-A-B) $.

  - 综合应用

    - $ A+B = A + (B-A) = (A-B) + B = (B-A) + (A-B) + AB $,

      即 $ A+B = A + \overline{A}B = \overline{A}B + A\overline{B} + AB $.

    - $ P(A+B) = P(A) + P(\overline{A}B) = P(\overline{A}B) + P(A\overline{B}) + P(AB) %= P(A-B) + P(B-A) + P(AB) $.

- 容斥原理

  - $ P(A+B) = P(A) + P(B) - P(AB) $, 或 $ P(AB) = P(A) + P(B) - P(A+B) $.
  - $ P(\overline{AB}) = P(\overline{A} +\overline{B}),\, P(\overline{AB}) + P(\overline{A}\,\overline{B}) = P(\overline{A}) + P(\overline{B}) $.
  - $ P(A+B+C) = P(A) + P(B) + P(C) - P(AB) - P(BC) - P(CA) + P(ABC) $.

- 恒等式

  - 化简含括号的运算
    - $ (A+B) + (A-B) = A+B $.
    - $ (A+B) - (A-B) = B $.
    - $ (A-B) + (B-A) = (A+B)-AB $.
    - $ (A-B) - (B-A) = A - B $.
    
  - 有用的概率恒等式
    - $ A-B = A-AB $, 或 $ A\overline{B} = A\overline{AB} $.
    
    - $ P(A-B) = P(A) - P(AB) $. (利用减法定理)
    
      $ P(AB) = P(A) - P(A\overline{B}) $.
    
    - $ P(A\overline{B}) = P(A) - P(AB) = P(A) - P(B) + P(\overline{A}B) $.

- 例题

  - 欧拉装错信封：$ \displaystyle P_n = \sum_{k=0}^n \dfrac{(-1)^k}{k!} $.
  - 先胜 $n$ 局者为胜, 甲 $a$ 胜 $b$ 负, 则甲胜的概率为：$ \displaystyle P_n(a, b) = \sum_{i=1}^{n-b} p^{n-a-1+i}(1-p)^{n-b-i} \binom{2n-a-b-1}{n-a-1+i} $.
  - 设 $n$ 个独立事件 $ \soneto{A}{n} $ 的概率分别为 $ \soneto{p}{n} $, 记 $ p = p_1+p_2+\cdots+p_n $, 则
    - $ \soneto{A}{n} $ 都不发生的概率小于 $ e^{-p} $.
    - $ \soneto{A}{n} $ 中至少发生 $k$ 个的概率小于 $ p^k/k! $.
  - 蒲丰投针问题：$ p = \dfrac{2l}{\pi a} $.

---

**概率的公理化定义**

1. 非负性.
2. 规范性.
3. 可列可加性.

**定理 1**	独立事件的交与并

> 若 $A$ 和 $B$ 均与 $C$ 独立, 则 $AB$ 与 $C$ 独立 $ \RLA $ $ A+B $ 与 $C$ 独立.

**证明**

- 法一

1. 必要性

$$
\begin{align}
P((A+B)C) &= P(AC + BC)
\\
&= P(AC) + P(BC) - P(ABC^2)
\\
&= P(C)( P(A)+P(B)-P(AB) )
\\
&= P(C)P(A+B).
\end{align}
$$

2. 充分性

$$
\begin{align}
P(ABC) &= P((AC)(BC))
\\
&= P(AC) + P(BC) - P((A+B)C)
\\
&= P(C)( P(A)+P(B)-P(A+B) )
\\
&= P(C)P(AB).
\end{align}
$$

- 法二

1. 必要性

$$
\begin{align}
P((A+B)C) &= P((A-B)C) + P((B-A)C) + P(ABC)
\\
&= P(AC-ABC) + P(BC-ABC) + P(ABC)
\\
&= P(A)P(C) - P(AB)P(C) + P(B)P(C) - P(AB)P(C) + P(AB)P(C)
\\
&= P(C)( P(A)+P(B)-P(AB) )
\\
&= P(C)P(A+B).
\end{align}
$$

2. 充分性

$$
\begin{align}
P(ABC) &= P((A+B)C) - P((A-B)C) - P((B-A)C)
\\
&= P(A+B)P(C) - P(AC-ABC) - P(BC-ABC)
\\
&= P(A+B)P(C) - P(A)P(C) + P(ABC) -P(B)P(C) + P(ABC)
\\
&= P(AC) + P(BC) - P((A+B)C)
\\
&= P(C)( P(A)+P(B)-P(A+B) )
\\
&= P(C)P(AB).
\end{align}
$$

**推论**	增加互斥条件的充分条件

> 若 $A$ 和 $B$ 均与 $C$ 独立, 且 $A$ 与 $B$ 互斥, 则 $AB$ 与 $ A+B $ 均与 $C$ 独立.

**定理 2**	相互独立的充要条件

> 设 $ 0 < P(A) < 1 $, 则 $ P(B \mid A) = P(B \mid \overline{A}) $ 是事件 $A, B$ 相互独立的充要条件.

**证明**

1. 必要性

$$
\begin{align}
P(B) &= P(AB) + P(\overline{A}B)
\\
&= P(A) P(B \mid A) + P(\overline{A}) P(B \mid \overline{A})
\\
&= P(B \mid A)
= P(AB) / P(A).
\end{align}
$$

2. 充分性

$$
\begin{align}
P(B \mid A) &= P(AB) / P(A) = P(B)
\\
&= P(AB) + P(\overline{A}B)
\\
&= P(A) P(B \mid A) + P(\overline{A}) P(B \mid \overline{A})
\\
&= P(B \mid \overline{A}).
\end{align}
$$

**推论**	相互独立的充要条件

> 设 $ 0 < P(A) < 1 $, 则 $ P(A \mid B) = P(\overline{A} \mid B) $ 是事件 $A, B$ 相互独立的充要条件.



# 第 2 章	随机变量及概率分布

常见分布更详细的信息请见笔记附录 ([源代码](概统附录.md) 或 [PDF](概统附录.pdf))

## 2.1	一维随机变量

### 2.1.1	离散型随机变量

概率函数, 分布表,

分布函数是一个右连续的不减函数.

<h4>1	二项分布</h4>

$ X \sim B(n, p) $.

理解: 事件发生的概率为 $p$, 则重复 $n$ 次试验, 事件发生的次数为 $x$.

概率分布：$ \displaystyle P(X=i) = b(i; n, p) = \binom{n}{i} p^i (1-p)^{n-i} $.

最可能数：$ x = \left\lfloor (n+1)p \right\rfloor $.

<h4>2	泊松分布</h4>

$ X \sim P(\lambda) $.

理解: 单位时间内事件平均发生 $\lambda$ 次, 则某一段单位时间内发生的次数为 $x$.

概率分布：$ \displaystyle P(X=i) = \lim_{n\to\infty} b(i; n, \frac{\lambda}{n}) = \dfrac{\e^{-\lambda}\lambda^i}{i!} $.

当二项分布满足 $n>50, p<0.1, np<5$ 时, 用泊松分布近似效果较好.

<h4>3	超几何分布</h4>

$ X \sim H(N, n, M) $.

理解: $N$ 件产品中有 $M$ 件次品, 从总体中抽 $n$ 件时次品的数量 $m$.

概率分布：$ \displaystyle P(X=m) = \binom{M}{m} \binom{N-M}{n-m} \left/ \binom{N}{n} \right. $.

<h4>4	负二项分布</h4>

$ X \sim NB(r, p) $.

理解: 合格率为 $p$, 抽取到 $r$ 个合格产品时, 抽到的不合格产品的个数 $x$.

概率分布：$ \displaystyle P(X=i) = d(i; r, p) = \binom{i+r-1}{r-1}p^r(1-p)^i $.

<h4>5	几何分布</h4>

$ X \sim GE(p) $.

理解: 合格率为 $p$, 抽取到第一个合格产品时, 抽到的不合格产品的个数 $x$.

概率分布：$ P(X=i) = p(1-p)^i $.

几何分布具有无记忆性.



### 2.1.2	连续型随机变量

概率分布函数, 概率密度函数

注：以下偏度系数定义为 $ \beta_1 = \mu_3/\mu_2^{3/2} $，峰度系数定义为 $ \beta_2 = \mu_4/\mu^2 $.

<h4>1	正态分布</h4>

$ X \sim N(\mu, \sigma^2) $.

概率密度函数：$ \displaystyle f(x) = (\sqrt{2\pi}\sigma)\inv \e^{-\tfrac{(x-\mu)^2}{2\sigma^2}} $.

标准正态分布：$ Y = (X-\mu)/\sigma \sim N(0,1) $.

$3\sigma$ 原则：0.6826，09544，9.9974.

上 $\alpha$ 分位数：$ \varPhi(z_\alpha) = 1-\alpha $.

<h4>2	指数分布</h4>

$ X \sim E(\lambda) $.

概率密度函数：$ f(x) = \begin{cases} \lambda\e^{-\lambda x}, & x>0, \\ 0, & x \le 0. \\ \end{cases} $

分布函数：$ F(x) = \begin{cases} 0, & x \le 0, \\ 1-\e^{-\lambda x}, & x>0. \\ \end{cases} $

指数分布具有无记忆性，即 $ P(X > m+t \mid X>m) = P(X>t) $.

<h4>3	威布尔分布</h4>

概率密度函数：$ f(x) = \begin{cases} \lambda\alpha x^{\alpha-1} \e^{-\lambda x^\alpha}, & x>0, \\ 0, & x \le 0. \end{cases} $

分布函数：$ F(x) = \begin{cases} 1-\e^{-\lambda x^\alpha}, & x>0, \\ 0, & x \le 0. \\ \end{cases} $

<h4>4	均匀分布</h4>

$ X \sim R(a, b) $.

概率密度函数：$ f(x) = \begin{cases} 1/(b-a), & a \le x \le b, \\ 0, & x<a \;或\; x>b. \end{cases} $

分布函数：$ F(x) = \begin{cases} 0, & x \le a, \\ (x-a)/(b-a), & a<x<b, \\ 1, & x \ge b. \end{cases} $

<h4>5	对数正态分布</h4>

$ \ln{X} \sim N(\mu, \sigma^2) $.

概率密度函数：$ f(x, \mu, \sigma) = \begin{cases} \pqty{x\sqrt{2\pi}\sigma} \exp\bqty{ -\dfrac{(\ln{x}-\mu)^2}{2\sigma^2} }, & x>0, \\ 0, & x \le 0. \end{cases} $

<h4>6	柯西分布</h4>

$ X \sim C(\gamma, x_0) $.

概率密度函数：$ f(x; x_0, \gamma) = \dfrac{1}{\pi} \cdot \dfrac{\gamma}{(x-x_0)^2 + \gamma^2}\; (-\infty < x < +\infty) $.

<h4>7	拉普拉斯分布</h4>

$ X \sim \text{La}(\mu, b) $.

概率密度函数: $ f(x) = \dfrac{1}{2\lambda}\e^{-\tfrac{\vqty{x-\mu}}{\lambda}} $.



## 2.2	多维随机变量

### 2.2.1	离散性随机向量

<h4>1	多项分布</h4>

$ X = (X_1, \cdots, X_n) \sim M(N; p_1, \cdots, p_n) $.
$$
P(X_1=k_1, X_2=k_2, \cdots, X_n=k_n) = \dfrac{N!}{k_1!k_2!\cdots k_n!} p_1^{k_1}p_2^{k_2}\cdots p_n^{k_n}.
$$

多项分布的边缘分布是二项分布.

$ (\soneto{X}{n}) \sim M(N; \soneto{p}{n}) \QRA X_1+X_2 \sim B(N;p_1+p_2) $.

### 2.2.2	连续型随机向量

<h4>1	矩形均匀分布</h4>

<h4>2	二维正态分布</h4>

$ X = (X_1, X_2) \sim N(a, b, \sigma_1^2, \sigma_2^2, \rho) $.
$$
f(x_1, x_2) = (2\pi\sigma_1\sigma_2\sqrt{1-\rho^2})\inv
\exp\bqty{
	- \frac{1}{2(1-\rho^2)} \pqty{
		\frac{(x_1-a)^2}{\sigma_1^2} -
		\frac{2\rho(x_1-a)(x_2-b)}{\sigma_1\sigma_2} +
		\frac{(x_2-b)^2}{\sigma_2^2}
	}
}.
$$

当且仅当 $\rho=0$ 时, $X_1$ 和 $X_2$ 独立.

**其它性质**

- 二维正态分布的边缘分布是正态分布.

- 二维正态分布的条件分布是正态分布.

  若 $ (X, Y) \sim N(a, b, \sigma_1^2, \sigma_2^2, \rho) $, 则给定 $X=x$ 时 $Y$ 的条件分布为
  $$
  N(b+\rho\sigma_2\sigma_1\inv (x-a),\, \sigma_2^2 (1-\rho^2)).
  $$

- 二维正态分布的边缘分布的和仍为正态分布

  若 $ (X_1, X_2) \sim N(\mu_1, \mu_2, \sigma_1^2, \sigma_2^2, \rho) $, 则 $ Y = X_1 + X_2 \sim N(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2 + 2\rho\sigma_1\sigma_2) $.

- 正态分布的联合分布<u>不一定</u>是二维正态分布.

- 相互独立的正态分布的和仍为正态分布

  若 $ X_i \sim N(\mu_i, \sigma_i^2) $, 则 $ X_1 + \cdots + X_n \sim N(\mu_1 + \cdots + \mu_n, \sigma_1^2 + \cdots + \sigma_n^2) $.

- 若 $Y = X_1 + X_2$ 服从正态分布, $X_1, X_2$ 独立, 则 $X_1, X_2$ 也是正态分布.

### 2.2.3	边缘分布

<h4>1	概念解释</h4>

- 随机向量的分布可以决定其任一分量的边缘分布, 但反之不亦然.
- 随机向量也叫作其边缘分布的 **联合分布**.
- 类似的有二维的边缘分布.

<h4>2	多项分布</h4>

$ (X_1, \cdots, X_n) \sim M(N; p_1, \cdots, p_n) $ 关于 $X_1$ 的边缘分布为 $ M(N, p_1) $.

<h4>3	二维正态分布</h4>

$ (X_1, X_2) \sim N(a, b, \sigma_1^2, \sigma_2^2, \rho) $ 关于 $X_1$ 和 $X_2$ 的边缘分布分别是 $ N(a, \sigma_1^2) $ 和 $ N(b, \sigma_2^2) $.



## 2.3	条件概率分布与随机变量的独立性

### 2.3.1	条件概率分布的概念

### 2.3.2	离散性随机变量的条件概率分布

<h4>1	多项分布</h4>

在给定 $ X_2 = k_2 $ 的条件下, $X_1$ 的条件分布为 $ B(N-k_2, p_1/(1-p_2)) $.

### 2.3.3	连续性随机变量的条件概率分布

$$
\begin{align}
& f_1(x_1 \mid a \le X_2 \le b) = \left. \int_a^b f(x_1, t_2)\dd{t_2} \right/ \int_a^b f_2(t_2)\dd{t_2}
\\ \\
& f(x_1, x_2) = f_2(x_2) f_1(x_1 \mid x_2)
\\
& f(x_1, \cdots, x_n) = g(x_1, \cdots x_k) h(x_{k+1}, \cdots, x_n \mid x_1, \cdots, x_k)
\\ \\
& f_1(x_1) = \int_{-\infty}^{+\infty} f_2(x_2) f_1(x_1 \mid x_2) \dd{x}_2
\end{align}
$$

正态变量的条件分布仍为正态. 正态分布条件分布的中心位置是
$$
m(x_1) = b + \rho \sigma_2 \sigma_1\inv (x_1 - a).
$$

### 2.3.4	随机变量的独立性

两个变量的独立 $ \QRLA f_1(x_1) = f_1(x_1 \mid x_2) $.

**定义 3.1**	连续型随机变量的相互独立 (独立)

> $ \soneto{X}{n} $ 相互独立 (独立) $ \QRLA f(x_1, \cdots, x_n) = f_1(x_1) \cdots f_n(x_n) $.

**定理 3.1**

> 连续变量独立 $\QRLA$ 对应的事件独立.

**定理 3.2**

> 若连续型随机向量 $(\soneto{X}{n})$ 的概率密度函数 $ f(\soneto{x}{n}) = g_1(x_1) g_2(x_2) \cdots g_n(x_n) $, 则 $\soneto{X}{n}$ 相互独立, 且 $ f_i(x_i) = Cg_i(x_i) $.

**定理 3.3**

> 若 $\soneto{X}{n}$ 相互独立,
> $$
> Y_1 = g_1(\soneto{X}{m}),\, Y_2 = g_2(X_{m+1}, X_{m+2}, \cdots, X_n),
> $$
> 则 $Y_1$ 和 $Y_2$ 独立.

**定义 3.2**	离散性随机变量的相互独立

> $\soneto{X}{n}$ 相互独立 (独立) 等价于
> $$
> \forall \soneto{a}{n}：P(X_1=a_1, \cdots, X_n=a_n) = P(X_1=a_1) \cdots P(X_n=a_n).
> $$

**示性函数**
$$
X = \begin{cases}
	1, & \text{当事件 $A$ 发生时,} \\
    0, & \text{当事件 $A$ 不发生时.}
\end{cases}
$$

## 2.4	随机变量的函数的概率分布

### 2.4.1	离散性分布

1. 多项分布 $ (\soneto{X}{n}) \sim M(N; \soneto{p}{n}) \QRA X_1+X_2 \sim B(N;p_1+p_2) $.
2. 二项分布 $ X_1 \sim B(n_1, p),\, X_2 \sim B(n_2, p) \QRA X_1 + X_2 \sim B(n_1+n_2, p) $.
3. 泊松分布 $ X_1 \sim P(\lambda_1),\, X_2 \sim P(\lambda_2) \QRA X_1 + X_2 \sim P(\lambda_1 + \lambda_2) $.

### 2.4.2	连续型分布

#### 1	单变量函数

##### 1.1	严格单调

若 $X$ 有密度函数 $f(x)$, $Y=g(X)$ 且该函数==严格单调==, 令 $ X = h(Y) $, 则 $Y$ 的概率密度函数为
$$
l(y) = f(h(y)) \vqty{h'(y)}.
$$

- $ X \sim N(\mu, \sigma^2) \QRA aX+b \sim N(a\mu + b, a^2\sigma^2) $.

##### 1.2	幂函数

若 $X$ 有密度函数 $f(x)$, $Y=X^n$, 其中 $n$ 为偶数, 则 $Y$ 的概率密度函数为
$$
l(y)= \vqty{ \dfrac{y^{\frac{1}{n}-1}}{n} } \bqty{
	f(y^\frac{1}{n}) + f(-y^\frac{1}{n})
}. \quad(n \text{ 是偶数})
$$

- 若 $ X \sim N(0, 1) $, 则 $Y=X^2$ 的密度函数为 $ l(y) = \begin{cases} \pqty{\sqrt{2\pi y}}\inv \e^{-y/2}, & y>0, \\ 0, & y \le 0. \end{cases} $

#### 2	多变量函数

以两个为例, 多变量是类似的.
$$
\begin{cases}
	Y_1 = g_1(X_1, X_2) \\
	Y_2 = g_2(X_1, X_2)
\end{cases}
\QRA
\begin{cases}
	X_1 = h_1(Y_1, Y_2) \\
	X_2 = h_2(Y_1, Y_2)
\end{cases}
$$
则雅可比行列式为
$$
J(y_1, y_2) = \begin{vmatrix}
	\displaystyle \pdv{h_1}{y_1} & \displaystyle \pdv{h_1}{y_1} \\
	\displaystyle \pdv{h_2}{y_1} & \displaystyle \pdv{h_2}{y_1} \\
\end{vmatrix},
$$
概率密度函数
$$
l(y_1, y_2) = f(h_1(y_1, y_2), h_2(y_1, y_2)) \vqty{J(y_1, y_2)}.
$$

### 2.4.3	随机变量和的密度函数

设 $(X_1, X_2)$ 的联合密度函数为 $f(x_1, x_2)$, 则 $Y = X_1 + X_2$ 的密度函数为
$$
l(y) = \int_{-\infty}^{+\infty} f(x, y-x) \dd{x}
= \int_{\infty}^{+\infty} f(y-x, x) \dd{x}.
$$

- 法一：固定 $y$ 后积分得分布函数, 再对 $y$ 求导得上式.
- 法二：补充 $Y_2=X_1$, 利用 2.4.2.2

---

- 二维正态分布的边缘分布的和仍为正态分布

  若 $ (X_1, X_2) \sim N(\mu_1, \mu_2, \sigma_1^2, \sigma_2^2, \rho) $, 则 $ Y = X_1 + X_2 \sim N(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2 + 2\rho\sigma_1\sigma_2) $.

- 相互独立的正态分布的和仍为正态分布

  若 $ X_i \sim N(\mu_i, \sigma_i^2) $, 则 $ X_1 + \cdots + X_n \sim N(\mu_1 + \cdots + \mu_n, \sigma_1^2 + \cdots + \sigma_n^2) $.

- 若 $Y = X_1 + X_2$ 服从正态分布, $X_1, X_2$ 独立, 则 $X_1, X_2$ 也是正态分布.

---

自由度为 $n$ 的皮尔逊卡方密度与 **卡方分布** $ X \sim \chi_n^2 $
$$
k_n(x) = \begin{cases}
\dfrac{
	\e^{-x/2} x^{(n-2)/2}
}{
	\Gamma\pqty{\cfrac{n}{2}} 2^{n/2}
}, & x>0,
\\
0, & x \le 0.
\end{cases}
$$

- 若 $\soneto{X}{n}$ 相互独立, 且有公共分布 $N(0, 1)^*$ (**独立同分布 iid**), 则 $ Y = X_1^2 + X_2^2 +\cdots + X_n^2 \sim \chi_n^2 $.

- 若 $ X_1 \sim \chi_m^2 $ 与 $ X_2 \sim \chi_n^2 $ 独立, 则 $ X_1 +X_2 \sim \chi_{m+n}^2 $.

- 若 $\soneto{X}{n}$ 相互独立, 且都服从指数分布 $E(\lambda)$, 则 $ X = 2\lambda(\splus{X}{n}) \sim \chi_{2n}^2 $.

- $ E(\chi_n^2) = n $.

- $ E(\chi_n^2)\inv = \dfrac{1}{n-2} $.

- $ E(\chi_n^2)^k = \dfrac{2^k\, \Gamma\pqty{\cfrac{n}{2}+k}}{\Gamma\pqty{\cfrac{n}{2}}}\; (k \in \Z) $.

- $ \Var(\chi_n^2) = 2n $.

  注意到方差是均值的两倍，可以以此检验是否为卡方分布.

---

:star: 若 $\soneto{X}{n}$ 独立同分布, 且有分布函数 $F(x)$ 和密度函数 $f(x)$, 则
$$
\begin{align}
	Y &= \max(\soneto{X}{n}) \sim n F^{n-1}(x) f(x), \\
	Z &= \min(\soneto{X}{n}) \sim n [1-F(x)]^{n-1} f(x).
\end{align}
$$

### 2.4.4	随机变量商的密度函数

设 $(X_1, X_2)$ 的联合密度函数为 $f(x_1, x_2)$, 则 $Y = X_2 / X_1$ 的密度函数为
$$
l(y) = \int_0^{+\infty} x_1 f(x_1, x_1y) \dd{x_1}.
$$

- 法一：固定 $y$ 后积分得分布函数, 再对 $y$ 求导得上式.
- 法二：补充 $Y_2=X_1$, 利用 2.4.2.2

---

设 $X_1, X_2$ 独立, $ X_1 \sim \chi_n^2,\, X_2 \sim N(0, 1),\, Y = X_2 / \sqrt{X_1 / n}  $, 则 $Y$ 的概率函数为
$$
t_n(y) = \dfrac{\Gamma((n+1)/2)}{\sqrt{n\pi}\,\Gamma(n/2)} \pqty{
	1 + \dfrac{y^2}{n}
}^{-\tfrac{n+1}{2}}.
$$
称为自由度为 $n$ 的 **$t$ 分布**.

- $ E(t_n) = 0\; (n>1) $.
- $ \Var(t_n) = \dfrac{n}{n-2}\; (n>2) $.

---

设 $X_1, X_2$ 独立, $ X_1 \sim \chi_n^2,\, X_2 \sim \chi_m^2,\, Y = \left. \dfrac{X_2}{m} \right/ \dfrac{X_1}{n} $, 则 $Y$ 的概率密度函数为

$$
f_{m,n}(y) = m^{m/2} n^{n/2} \dfrac{\Gamma\pqty{\dfrac{m+n}{2}}}{\Gamma\pqty{\dfrac{m}{2}} \Gamma\pqty{\dfrac{n}{2}}} y^{m/2-1} (my+n)^{-(m+n)/2} \quad (y>0)
$$
称为自由度为 $(m, n)$ 的 **$F$ 分布**.

- $ E(f_{m,n}) = \dfrac{n}{n-2}\; (n>2) $.
- $ \Var(f_{m,n}) = \dfrac{2n^2(m+n-2)}{m(n-2)^2(n-4)} $.

---

## 注意事项

- 概率密度函数在某点的取值必为 0, 如果非零, 则不存在这样的概率密度函数. 即混合型随机变量没有概率密度函数.
- 计算随机变量的函数的概率分布时，注意==单调性==和==值域是否重叠==.









# 第 3 章	随机变量的数字特征

## 3.1	数学期望与中位数

### 3.1.1	数学期望的定义

### 3.1.2	数学期望的性质

**定理 1.1**	随机变量之和的期望

> 若干个随机变量之和的期望, 等于各变量的期望之和, 即
> $$
> E(\splus{X}{n}) = E(X_1) + E(X_2) + \cdots E(X_n).
> $$

**定理 1.2**	随机变量之积的期望

> 若干个==独立==随机变量之积的期望, 等于各变量的期望之积, 即
> $$
> E(X_1X_2 \cdots X_n) = E(X_1) E(X_2) \cdots E(X_n).
> $$

**定理 1.3**	随机变量函数的期望

> 设随机变量 $X$ 为离散型, 有分布 $P(X=a_i) = p_i, i = \oneton$, 或者为连续型, 有概率密度函数 $f(x)$, 则
> $$
> E(g(X)) = \sum_{i} g(a_i) p_i \text{ 或 } \int_{-\infty}^{+\infty} g(x)f(x)\dd{x} \quad \text{(若求和或极限存在.)}
> $$

### 3.1.3	条件数学期望 (条件均值)

条件期望 $E(Y \mid x)$ 称为 $Y$ 对 $X$ 的回归函数.
$$
E(Y \mid x) = \int_{-\infty}^{+\infty} yf(y \mid x) \dd{y}.
$$
期望等于条件期望的期望
$$
\begin{align}
	E(Y) &= \int_{-\infty}^{+\infty} E(Y \mid x) f_1(x) \dd{x}
	\\
	&= E[E(Y \mid X)]
\end{align}
$$

### 3.1.4	中位数

- 中位数总是存在，均值则不然.
- 中位数可以不唯一.

## 3.2	方差与矩

### 3.2.1	方差和标准差

1. $ \Var(X) = E(X-EX)^2 = E(X^2) - (EX)^2 $.

2. $ \Var(aX+b) = a^2\Var(X) $.

3. ==独立==随机变量：$ \Var(X_1 + \cdots + X_2) = \Var(X_1) + \cdots + \Var(X_2) $.

4. $ E[(X-c)^2] = \Var(X) + (EX - c)^2 $.

   $ \Var(X) = \min\limits_c\Bqty{E[(X-c)^2]} $, 当且仅当 $c=EX$ 时取等.

   注: 令 $c=0$ 即得 1. 式.

### 3.2.2	矩

**定义**

1. $X$ 关于 $c$ 点的 $k$ 阶矩：$ E[(X-c)^k] $.
2. $k$ 阶原点矩：$ \alpha_k = E(X^k) $.
3. $k$ 阶中心距：$ \mu_k = E[(X-EX)^k] $.

**特例**

1. $ \alpha_1 = E(X) $.
2. $ \mu_1 = 0 $.
3. $ \mu_2 = \Var(X) $.

**偏度系数**	$ \beta_1 = \dfrac{\mu_3}{\mu_2^{3/2}} $.

**峰度系数**	$ \beta_2 = \dfrac{\mu_4}{\mu_2^2} $.

正态分布 $ N(\mu, \sigma^2) $ 的峰度系数为 $3$，故有时定义峰度系数为 $ \mu_4 \left/ \mu_2^2 \right. - 3 $.

## 3.3	协方差与相关系数

### 3.3.1	协方差

1. $ \Cov(X, Y) = E[(X-EX)(Y-EY)] $.
2. $ \Cov(X, Y) = \Cov(Y, X) $.
3. $ \Cov(a_1X+b_1, a_2Y+b_2) = a_1 a_2 \Cov(X, Y) $.
4. $ \Cov(X, Y) = \Var(X + Y) - \Var(X) - \Var(Y) $.
5. $ \Cov(X, Y) = E(XY) - E(X)E(Y) $.
6. 若 $X, Y$ 独立，则 $ \Cov(X, Y) = 0 $.
7. $ [\Cov(X, Y)]^2 \le \sigma_1^2 \sigma_2^2 $，且当且仅当 $ Y = a + bX $ 时取等.

**施瓦茨不等式**	$ E(X^2) E(Y^2) \ge (E(XY))^2 $, 当且仅当具有线性关系即 $ aX + bY = 0 $ 时取等. (即上述第 6 点令 $ EX = EY = 0 $)

### 3.3.2	相关系数

1. $ \Corr(X, Y) = \Cov(X, Y) / (\sigma_1 \sigma_2) $.
   - 相关系数不受单位影响.
2. 若 $X, Y$ 独立，则 $ \Corr(X, Y) = 0 $.
   - 若 $ \Corr(X, Y)=0$ 则称 $X$ 与 $Y$ **不相关**.
3. $ \vqty{\Corr(X, Y)} \le 1 $，且当且仅当 $X$ 和 $Y$ 有严格线性关系时取等.
   - 相关系数又称为线性相关系数.
4. 最小二乘及其均方误差.

$$
\begin{align}
E[(Y-a-bX)^2] &\equiv E[(Y-m_2) - b(X-m_1) - c]^2
\\
&= \sigma_2^2 + b^2\sigma_1^2 - 2b \Cov(X, Y) + c^2
\\
&\ge \sigma_2^2 + b^2\sigma_1^2 - 2b \Cov(X, Y)
\end{align}
$$

$$
\begin{align}
& b = \Cov(X, Y) / \sigma_1^2
= \sigma_1\inv \sigma_2 \Corr(X, Y)
\equiv \sigma_1\inv \sigma_2 \rho
\\
& L(X) = m_2 - \sigma_1\inv \sigma_2 \rho m_1 + \sigma_1\inv \sigma_2 \rho X
\end{align}
$$

$$
\begin{align}
E[(Y-L(X))^2] &= \sigma_2^2 + b^2\sigma_1^2 - 2b \Cov(X, Y)
& (由最上式)
\\
&= \sigma_2^2 (1-\rho^2)
\end{align}
$$

---

**二维正态分布**

若 $ (X, Y) \sim N(a, b, \sigma_1^2, \sigma_2^2, \rho) $，则

1. 即使允许用任何函数 $M(X)$ 逼近 $Y$，则所得到的最佳逼近仍是 $L(X)$，故只需考虑线性逼近已足够.
2. 对于二维正态分布, $ \Corr(X, Y) = \rho $，即 $ \Corr(X, Y) = 0 $ 可推出二者独立.

## 3.4	大数定理和中心极限定理

### 3.4.1	大数定理

**马尔科夫不等式**	若 $Y$ 为只取非负值的随机变量，则对 $ \forall \ve > 0 $，有
$$
P(Y \ge \ve) \le E(Y) / \ve.
$$
**切比雪夫不等式**	若 $ \Var(Y) $ 存在，则
$$
P\pqty{
	\vqty{Y-EY} \ge \ve
} \le \Var(Y) / \ve^2.
$$
**大数定理**	设 $ \soneto{X}{n} $ 是独立同分布的随机变量，记它们的公共均值为 $a$，方差存在并记为 $\sigma^2$，则对 $ \forall \ve > 0 $，有
$$
\lim_{n\to\infty} P\pqty{
	\vqty{\overline{X}_n - a} \ge \ve
} = 0.
$$
**伯努利大数定理**	即大数定理的特例（频率收敛于概率）
$$
\lim_{n\to\infty} P\pqty{
	\vqty{p_n-p} \ge \ve
} = 0.
$$

- 大数定理中无需假定 $X_i$ 的方差存在也可以证明，不必同分布，甚至可以不独立.

### 3.4.2	中心极限定理

[应用](# 4.4.3	大样本法) 

**林德伯格—莱维定理**	设 $\soneto{X}{n}$ 为独立同分布的随机变量，$ E(X_i) = a,\, \Var(X_i) = \sigma^2\; (0 < \sigma^2 < \infty) $，则对任何实数 $x$，有
$$
\lim_{n\to\infty} P\pqty{
	\dfrac{1}{\sqrt{n}\sigma} \pqty{
		\splus{X}{n} - na
	} \le x
} = \varPhi(x).
$$
**棣莫弗—拉普拉斯定理**	上式的特例，当 $ P(X_i=1)=p,\,P(X_i=0)=1-p\; (0<p<1) $ 时，对任何实数 $x$，有
$$
\lim_{n\to\infty} P\pqty{
	\dfrac{1}{\sqrt{np(1-p)}} \pqty{
		\splus{X}{n} - na
	} \le x
} = \varPhi(x).
$$
**估值公式**
$$
P(t_1 \le \splus{X}{n} \le t_2) \approx \varPhi(y_2) - \varPhi(y_1).
$$
其中 $ y_i = (t_i - np) \left/ \sqrt{np(1-p)} \right. $，或修正为
$$
\left\{
\begin{align}
	& y_1 = \left. \pqty{t_i - \dfrac{1}{2} - np} \right/ \sqrt{np(1-p)}, \\
	& y_2 = \left. \pqty{t_i + \dfrac{1}{2} - np} \right/ \sqrt{np(1-p)}.
\end{align}
\right.
$$




### 例题

分鞋：例 1.7 和 2.4



# 第 4 章	参数估计

## 4.1	数理统计学的基本概念

**总体**（母体）是概率分布族的一员.

**总体分布**	离散性（概率函数），连续型（概率密度函数）

**单参数分布族**.

**非参数总体**.

**样本大小**（容量）

**统计量**	只依赖于样本，而不依赖于其参数.

**样本均值**	$ a_1 = (\splus{X}{n})/n $.

**样本方差**	$ S^2 = \displaystyle \sum_{i=1}^n (X_i - \overline{X})^2 / (n-1) $.

**样本原点矩**	$ a_k = (\splus{X^k}{n}) / n $.

**样本中心矩**	$ m_k = \displaystyle \sum_{i=1}^n (X_i - \overline{X})^k / n $.

**经验分布函数**	$ F_n(x) = \Bqty{ \soneto{X}{n} \text{ 中不大于 $x$ 的个数} } / n $.

- 矩称为理论矩，样本矩称为经验矩，即经验分布函数的矩.
- $ m_2 = \dfrac{n-1}{n} S^2 $.

**次序统计量**	$ X_{(1)} \le X_{(2)} \le \cdots \le X_{(n)} $.

**样本中位数**	$ \hat{m} = \begin{cases} X_{((n+1)/2)}, & n \text{ 为奇数,} \\ (X_{(n/2)} + X_{(n/2+1)}) / 2, & n \text{ 为偶数.} \end{cases} $

## 4.2	点估计

### 4.2.1	矩估计法

$$
\alpha_m = \inti x^m f(x; \theta_1, \cdots, \theta_2) \dd{x}
\approx a_m = \sum_{i=1}^n X_i^m / n
$$

取 $ m = \oneto{k} $，联立方程组即得 $ \theta_i \approx \hat{\theta}_i(X_1, \cdots, X_n) $.

**变异系数**	$ \sigma/\mu $.

### 4.2.2	极大似然估计法

样本 $(\soneto{X}{n})$ 的总体分布函数为
$$
L(x_1, \cdots, x_n,; \theta_1, \cdots, \theta_k)
= f(x_1; \theta_1, \cdots, \theta_k) f(x_2; \theta_1, \cdots, \theta_k) \cdots f(x_n; \theta_1, \cdots, \theta_k)
\\
L(X_1, \cdots, X_n; \theta_1^*, \cdots, \theta_k^*) = 
\max_{\theta_1, \cdots, \theta_k} L(X_1, \cdots, X_n; \theta_1, \cdots, \theta_k)
$$
欲得到极大似然估计，解如下似然方程组
$$
\pdv{\ln{L}}{\theta_i} = 0\quad (i = \oneto{k})
$$

### 4.2.3	贝叶斯估计法

先验分布，先验概率. 允许使用主观概率.

设总体有概率密度 $f(X, \theta)$，抽样本 $ \soneto{X}{n} $，则 $ (\theta, X_1, \cdots, X_n) $ 的联合密度为
$$
h(\theta) f(X_1, \theta) \cdots f(X_n, \theta)
$$
由此算出 $(\soneto{X}{n})$ 的边缘密度为
$$
p(\soneto{X}{n}) = \int h(\theta) f(X_1, \theta) \cdots f(X_n, \theta) \dd\theta
$$
从而得出 $\theta$ 在给定 $\soneto{X}{n}$ 的条件密度为
$$
h(\theta \mid X_1, \cdots, X_n) = h(\theta) f(X_1, \theta) \cdots f(X_n, \theta) / p(X_1, \cdots, X_n)
$$

一般去上式的均值作为估计, 即
$$
\tilde{\theta} = E(h(\theta \mid \soneto{X}{n})).
$$

---

$h(\theta)$ 一般是概率函数，即满足 $ h(\theta) \ge 0,\, \dint h(\theta) \dd\theta = 1 $.

但对于积分域为无穷区间，或一些特定的分布，可以采用其它函数，比如 $ h(\theta) = 1 $，或直接取为<u>先验密度</u>等. 此时 $h(\theta)$ 称为 "广义先验密度".

---

根据 $n$ 次独立试验中事件 $A$ 发生的次数 $X$ 去估计其发生的概率 $p$，按照 "同等无知" 原则（贝叶斯原则），由上述方法积分得
$$
\tilde{p} = \dfrac{X+1}{n+2}.
$$

---

- 估计正态分布 $N(\mu, \sigma^2)$ 中的 $\mu$ 时，取 $h(\mu) = 1$；
- 估计正态分布 $N(\mu, \sigma^2)$ 中的 $\sigma$ 时，取 $ h(\sigma) = \sigma\inv $；
- 估计指数分布 $ E(\lambda) $ 中的 $\lambda$ 时，取$ h(\lambda) = \lambda\inv $.

---

由先验分布 $ N(\mu. \sigma^2) $ 估计正态总体 $ N(\theta, 1) $ 中的 $\theta$ 为（取 $h(\theta)$ 为先验密度）
$$
\tilde{\theta} = \dfrac{n}{n+\sigma^{-2}} \overline{X\,} + \dfrac{\sigma^{-2}}{n+\sigma^{-2}} \mu.
$$
<span style="background-color: #eeeeee; color: #777777">不知道为什么将正态总体分布的方差取为 1，有什么实际应用吗？</span>

## 4.3	点估计的优良性准则

估计的整体性能

1. 无偏性.
   1. 没有系统性的偏差, 即误差的均值为零.
   2. 各次估计的均值依概率收敛至被估计值.
2. 数量指标 (如均方误差).

### 4.3.1	估计量的无偏性

无偏估计量 $\hat{g}$ 须满足
$$
E_{\theta_1, \cdots, \theta_k} [\hat{g}(X_1, \cdots, X_n)] = g(\theta_1, \cdots, \theta_k).
$$

- $m = \overline{X}$ 是 $E(X)$ 的无偏估计.
- 如果总体均值未知, 则 $ S^2 = \insum\dfrac{(X_i-\overline{X})^2}{n-1} $ 是 $\Var(X)$ 的无偏估计.
- 如果总体均值已知, 则 $ m_2 = \nsum \dfrac{(X_i - \overline{X})^2}{n} $ 是 $\Var(X)$ 的无偏估计.

由 $ \sigma^2 = E(S^2) = \Var(S) + (ES)^2 $ 知, $S$ 总是 $\sigma$ 系统性偏低的估计.

- :star: (看思路) 对于正态分布总体 $N(\mu, \sigma^2)$, 由 $ (n-1)S^2 / \sigma^2 \sim \chi_{n-1}^2 $ 算出
  $$
  S/\sigma \sim g(s) = \begin{cases}
  	\dfrac{
  		(n-1)^{\tfrac{n-1}{2}}
  	}{
  		2^{\tfrac{n-3}{2}} \Gamma\pqty{\cfrac{n-1}{2}}
  	}, & s>0 \\
  	0 & s \le 0.
  \end{cases}
  $$
  计算 $E(S) = \sigma \intoi sg(s) \ds$, 故 $\sigma$ 的一个无偏估计是
  $$
  \tilde{\sigma} = 
  \sqrt{\dfrac{n-1}{2}} \dfrac{
  	\Gamma\pqty{\dfrac{n-1}{2}}
  }{
  	\Gamma\pqty{\dfrac{n}{2}}
  } S.
  $$
  
- <font color="red">无偏估计不一定好</font>, 比如 $X\sim P(\lambda)$, 则 $g(\lambda) = \e^{-2\lambda}$ 唯一的无偏估计为
  $$
  \hat g(X) = \begin{cases}
  	1, & X \text{ 为偶数}, \\
  	-1, & X \text{ 为奇数}.
  \end{cases}
  $$

### 4.3.2	最小方差无偏估计

#### 1	均方误差

$$
\begin{align}
M_{\hat{\theta}}(\theta) &= E_\theta \bqty{
	\hat{\theta}(X_1, \cdots, X_n) - \theta
}^2
\\
&= \Var_\theta(\hat{\theta}) + \bqty{
	E_\theta(\hat{\theta}) - \theta
}^2
\end{align}
$$

#### 2	最小方差无偏估计 (MVU 估计)

注意是最小方差, 而不是最小均方误差. (Minimum Variance Unbiased)

#### 3	克拉美 - 劳不等式

对于单参数情况 $f(x, \theta)$, 为估计 $g(\theta)$, 记 **费歇尔信息量** 为
$$
\begin{align}
I(\theta) &= E \bqty{\pqty{
	\left.
		\pdv{f(x, \theta)}{\theta}
	\right/ f(x, \theta)
}^2}
\\
&= \int \bqty{
	\left. \pqty{
		\pdv{f(x, \theta)}{\theta}
	}^2 \right/ f(x, \theta)
} \dx
& \text{(连续的总体分布)}
\\
&= \sum_{i} \left. \pqty{
	\pdv{f(a_i, \theta)}{\theta}
}^2 \right/ f(a_i, \theta)
& \text{(离散的总体分布)}
\end{align}
$$
则对任一无偏估计 $\hat{g} = \hat{g}(\soneto{X}{n})$, 有 **克拉美 - 劳不等式**:
$$
\Var_\theta(\hat{\theta}) \ge (g'(\theta))^2 / (nI(\theta)).
$$

- <font color="red">MVU 的均方误差不一定是最小的</font>, 如对于正态分布 $N(\mu, \sigma^2)$, 其中 $\mu$ 已知, 则 $m_2$ 是 MVU 估计, 但 $ E(m_2 - \sigma^2)^2 = \dfrac{2\sigma^4}{n} > E(\dfrac{m_2}{n+1} - \sigma^2)^2 = \dfrac{2\sigma^4}{n+1} $.
- 若 $\hat\theta_1$ 和 $\hat\theta_2$ 都是 $\theta$ 的 MVU 估计, 则 $ a\hat\theta_1 + b\hat\theta_2 + c $ 是 $(a+b)\theta + c$ 的 MVU 估计. :star: :star: (利用第三章定理 3.1, 2°)
- 若 $ E(X) = \theta,\, \insum c_i = 1 $, 则 $ \insum c_iX_i $ 是 $\theta$ 的无偏估计, 并且当且仅当 $ c_i = \dfrac{1}{n} $ 时, 其为 MVU 估计.

### 4.3.3	估计量的相合性与渐进正态性

#### 1	相合性

如果当样本大小 $n$ 无限增加时, 估计量 $T(\soneto{X}{n})$ 依概率收敛于被估计值, 则称该估计量是相合估计, 即
$$
\forall \ve>0: \nlim P_{\theta_1, \cdots, \theta_k} \pqty{
	\vqty{
		T(X_1, \cdots, X_n) - g(\theta_1, \cdots, \theta_n)
	} \ge \ve
} = 0.
$$
具有相合性的例子: $ m(n),\, m_2(n) $, 绝大多数极大似然估计等等.

#### 2	渐进正态性

- 大样本性质
  - 相合性
  - 渐进正态性
- 小样本性质
  - 无偏性

## 4.4	区间估计

### 4.4.1	基本概念

**奈曼理论** 的原则: 先保证可靠度, 再提升精度.

称区间估计 $[\hat{\theta}_1, \hat{\theta}_2]$ 的 **置信系数** 为 $1-\alpha$, 如果
$$
\exist \alpha>0,\, \forall \theta:
P_\theta \pqty{
	\hat{\theta}_1 (X_1, \cdots, X_n) \le \theta \le
	\hat{\theta}_2 (X_1, \cdots, X_n)
} = 1-\alpha.
$$
称区间估计 $[\hat{\theta}_1, \hat{\theta}_2]$ 的 **置信水平** 为 $1-\alpha$, 如果
$$
\exist \alpha>0,\, \forall \theta:
P_\theta \pqty{
	\hat{\theta}_1 (X_1, \cdots, X_n) \le \theta \le
	\hat{\theta}_2 (X_1, \cdots, X_n)
} \ge 1-\alpha.
$$
$\alpha$ 一般取为 0.1, 0.05, 0.01, 0.001.

---

区间估计的研究对象:

1. 置信系数或置信水平.
2. 区间长度.
3. 区间右端点与左端点之比.

### 4.4.2	枢轴变量法

上 $\beta$ 分位点: $F(v_\beta) = 1-\beta$.

下 $\beta$ 分位点: $F(w_\beta) = \beta$.

上 $\beta$ 分位点就是下 $1-\beta$ 分位点.

统计三大分布的上 $\beta$ 分位点记为: $ \chi_n^2(\beta),\, t_n(\beta),\, f_{n, m}(\beta) $.

---

利用上 $\beta$ 分位点 $w_\beta$ 寻找区间估计的 **枢轴变量法**:

1. 找一个与被估计参数 $g(\theta)$ 有关的统计量 $T$.
2. 找 **枢轴变量** $S(T, g(\theta))$, 使其分布 $F$ 与 $\theta$ 无关.
3. $ a \le S(T, g(\theta)) \le b \QRLA A \le g(\theta) \le B $.
4. $ P(w_{1-\alpha/2} \le S(T, g(\theta)) \le w_{a/2}) = 1-\alpha $.

---

一样本 $t$ 区间估计, 为保证长度 $ 2S t_{n-1} (\alpha/2) / \sqrt{n} \le L $, 斯泰因提出了 **两阶段抽样** 的方法, 其中追加抽样的次数为
$$
m = \begin{cases}
	0, & n \le [4 t_{n-1}^2(\alpha/2) S^2 / L^2] + 1, \\
	n-1 - [4 t_{n-1}^2(\alpha/2) S^2 / L^2],
	& n \gt [4 t_{n-1}^2(\alpha/2) S^2 / L^2] + 1.
\end{cases}
$$
记两次样本全体的均值为 $\tilde{X}$, 则区间估计 $ [\tilde{X} - L/2,\, \tilde{X} + L/2] $ 有置信系数 $1-\alpha$.

### 4.4.3	大样本法

大样本区间估计: 利用 [中心极限定理](# 3.4.2	中心极限定理) 与枢轴变量法.

例如, 一般的, 设总体有均值 $\theta$, 方差 $\sigma^2$, 并且都位置, 从样本 $\soneto{X}{n}$ 做 $\theta$ 的区间估计. 由于样本均方差 $S$ 是 $\sigma$ 的祥和估计, 利用中心极限定理, 当 $n$ 足够大时, 有
$$
\sqrt{n} (\overline{X} - \theta) / S \sim N(0, 1).
$$
以此为枢轴变量, 于是有区间估计
$$
\bqty{
	\overline{X} - S u_{\alpha/2} / \sqrt{n},\,
	\overline{X} + S u_{\alpha/2} / \sqrt{n}
}.
$$

---

对于二项分布, 当 $\alpha = 0.05,\,n\ge40$ 时, 有区间长度 $\theta_2 - \theta_1 \le 0.3$.

### 4.4.4	置信界

置信系数 (水平) 为 $\alpha$ 的置信上界 $\overline{\theta}$ 和置信下界 $\underline{\theta}$:
$$
\begin{align}
& \forall \theta:
P_\theta (\overline{\theta}(\soneto{X}{n}) \ge \theta) = 1-\alpha
\\
& \forall \theta:
P_\theta (\underline{\theta}(\soneto{X}{n}) \le \theta) = 1-\alpha
\end{align}
$$

### 4.4.5	贝叶斯法

即寻找 $\hat\theta_1,\, \hat\theta_2$, 使得
$$
\begin{align}
& \int_{\hat\theta_1}^{\hat\theta_2} h(\theta \mid X_1, \cdots, X_n) \dd{\theta} = 1-\alpha
& \text{(区间估计)}
\\
& \int_{-\infty}^{\hat\theta} h(\theta \mid X_1, \cdots, X_n) \dd{\theta} = 1-\alpha
& \text{(置信上界)}
\\
& \int_{\hat\theta}^{+\infty} h(\theta \mid X_1, \cdots, X_n) \dd{\theta} = 1-\alpha
& \text{(置信下界)}
\end{align}
$$
区间估计中确定 $\theta_1,\, \theta_2$ 的方法 (原则):

1. 使 $\hat\theta_2 - \hat\theta_1$ 最小.
2. 使 $ \hat\theta_2 / \hat\theta_1 $ 最小.
3. 取置信水平为 $\alpha/2$ 的置信上下界.



# 第 5 章	假设检验

## 5.1	问题提法和基本概念

### 5.1.1	例子与问题提法

原假设 (零假设, 解消假设), 对立假设 (备择假设).

检验统计量, 接受域, 否定域 (临界域), 临界值.

简单假设, 复合假设. 赘余参数.

### 5.1.2	功效函数

设 $H_0$ 为原假设, $\varPhi$ 是基于样本 $\soneto{X}{n}$ 而对 $H_0$ 做的一个检验, 则其 **功效函数** 是未知参数 $\soneto{\theta}{n}$ 的函数:
$$
\beta_\varPhi(\soneto{\theta}{n}) = P_{\soneto{\theta}{n}} (在检验\ \varPhi\ 之下,\, H_0\ 被否定)
$$

- 当 $ (\soneto{\theta}{n}) \in H_0 $ 时, 上式越小越好.
- 当 $ (\soneto{\theta}{n}) \in H_1 $ 时, 上式越大越好, 此时称为功效函数.

### 5.1.3	两类错误, 检验的水平

两类错误

1. $H_0$ 正确, 但被否定.
2. $H_0$ 错误, 但被接受.

$$
\begin{align}
\alpha_{1\varPhi} (\soneto{\theta}{k}) &= \begin{cases}
	\beta_{\varPhi} (\soneto{\theta}{k}),
	& (\soneto{\theta}{k}) \in H_0,
	\\
	0 & (\soneto{\theta}{k}) \in H_1.
\end{cases}
\\
\alpha_{2\varPhi} (\soneto{\theta}{k}) &= \begin{cases}
	0, & (\soneto{\theta}{k}) \in H_0,
	\\
	1 - \beta_{\varPhi} (\soneto{\theta}{k}),
	& (\soneto{\theta}{k}) \in H_1.
\end{cases}
\end{align}
$$

---

$H_0$ 的一个水平为 $\alpha$ 的检验 $\varPhi$:
$$
\beta_\varPhi (\soneto{\theta}{k}) \le \alpha \quad (对任何\ (\soneto{\theta}{k}) \in H_0).
$$
并使 $\alpha$ 仅可能小. 即固定第一类错误概率的原则.

### 5.1.4	一致最优检验

假设检验问题 $H_0:H_1$ 的一个水平为 $\alpha$ 的一致最优检验 $\varPhi$: 即对任何一个其它水平 $\alpha$ 的检验 $g$ 有
$$
\beta_\varPhi (\soneto{\theta}{k}) \ge \beta_g (\soneto{\theta}{k}) \quad (对任何\ (\soneto{\theta}{k}) \in H_1).
$$

- 在总体分布只依赖于一个参数 $\theta$, 而原假设 $H_0$ 是 $\theta \le \theta_0$ 或 $\theta \ge \theta_0$ 时, 一致最优检验存在.

5.2	重要参数检验

5.2.1	正态总体均值的检验

1	方差 σ^2^ 已知

2	方差啊 σ^2^ 未知

5.2.2	两个正态总体均值差的检验

5.2.3	正态分布方差的检验

5.2.4	指数分布参数的检验

5.2.5	二项分布参数的检验

5.2.6	泊松分布参数的检验

5.2.7	大样本检验

5.2.8	贝叶斯方法

5.3	拟合优度检验

5.3.1	理论分布完全已知且只取有限个值的情况

5.3.2	理论分布只含有限个值但不完全已知的情况

5.3.3	对列联表的应用

5.3.4	总体分布为一般分布的情况











